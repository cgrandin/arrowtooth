---
title: "Arrowtooth Flounder (*Atheresthes stomias*) Stock Assessment for the West Coast of British Columbia in 2021"
subtitle: "Assessment model"
author: "C. Grandin, S. Anderson, P. English"
institute: "DFO"
date: "Slides compiled on `r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: ["default", "xaringan-themer.css", "code-custom.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9'
---

background-image: url(figures/arrowtooth_flounder.jpeg)

```{r setup, echo=FALSE, cache=FALSE, message=FALSE, results='hide', warning=FALSE}
library(knitr)
if (is_latex_output()) {
  knitr_figs_dir <- "knitr-figs-pdf/"
  knitr_cache_dir <- "knitr-cache-pdf/"
  fig_out_type <- "png"
} else {
  knitr_figs_dir <- "knitr-figs-docx/"
  knitr_cache_dir <- "knitr-cache-docx/"
  fig_out_type <- "png"
}
fig_asp <- 0.618
fig_width <- 8
fig_out_width <- "5.5in"
fig_dpi <- 180
fig_align <- "center"
fig_pos <- "H"
user <- Sys.info()[["user"]]
opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  results = 'hide',
  comment = "#>",
  fig.path = knitr_figs_dir,
  cache.path = knitr_cache_dir,
  fig.asp = fig_asp,
  fig.width = fig_width,
  out.width = fig_out_width,
  echo = FALSE,
  # autodep = isTRUE(user %in% "seananderson"),
  # cache = isTRUE(user %in% "seananderson"),
  cache.comments = FALSE,
  dev = fig_out_type,
  dpi = fig_dpi,
  fig.align = fig_align,
  fig.pos = fig_pos
)
options(
  # Prevent xtable from adding a timestamp comment to the table code
  # it produces
  xtable.comment = FALSE,
  # Don't allow kableExtra to load packages, we add them manually in
  # csasdown
  kableExtra.latex.load_packages = FALSE,
  # Stop chunk output (echo) running into the margins
  width = 80,
  # Don't use scientific notation (stops tables from showing 1.2e3, etc.)
  scipen = 999)
# Fixes weird bug where knitr::include_graphics() thinks the non-git folder
# is relative
options(knitr.graphics.rel_path = FALSE)
```

```{r library-setup, cache = FALSE, fig.keep='none'}
# Libraries in alphabetical order

library(devtools)
library(dplyr)
if(user == "grandin"){
  load_all("d:/github/pbs-assess/gfiscamutils")
  load_all("d:/github/pbs-assess/csasdown")
}else if(user == "seananderson"){
  library(gfiscamutils)
  load_all("~/src/gfiscamutils/")
  load_all("~/src/csasdown/")
  load_all("~/src/gfplot/")
} else {
  library(gfiscamutils)
  library(csasdown)
}
library(gfplot)
library(gfutilities)
library(ggplot2)
library(gridExtra)
library(here)
library(kableExtra)
library(purrr)
library(rosettafish)
library(tidylog, warn.conflicts = FALSE)
devtools::load_all(".")
```

```{r include = FALSE}
build_rds <- FALSE
# Don't load the models if they already exist
if(!exists("models") || !exists("drs"))
  source(here("doc/load-models.R"), local = knitr::knit_global())
```

```{r data-setup, cache.lazy = FALSE}
# This chunk requires that the chunk above that loads load-models.R is run

bc <- "British Columbia"
sp <- "Arrowtooth Flounder"
iscam <- "ISCAM"

month_fishing_starts <- 2
day_fishing_starts <- 21

data_dir <- file.path(drs$nongit_dir, "data")
data_output_dir <- file.path(drs$nongit_dir, "data-output")

if(!dir.exists(data_dir)){
  stop("Data directory does not exist: ", data_dir, call. = FALSE)
}
iphc_file <- file.path(data_dir, "iphc-survey-index.rds")
if(!file.exists(iphc_file)){
  stop("IPHC file does not exist: ", iphc_file, call. = FALSE)
}
discard_cpue_file <- file.path(data_dir,
"cpue-predictions-arrowtooth-flounder-modern-3CD5ABCDE-discard-july-26-feb-fishing-year.csv")
#"cpue-predictions-arrowtooth-flounder-modern-3CD5ABCDE-discard-july-26-jan-1-year.csv")
if(!file.exists(discard_cpue_file)){
  stop("Discard CPUE file does not exist: ", discard_cpue_file, call. = FALSE)
}
stitched_syn_file <- file.path(data_dir, "stitched-syn-index.rds")
if(!file.exists(stitched_syn_file)){
  stop("Stitched Synoptics file does not exist: ", stitched_syn_file, call. = FALSE)
}

iphc <- readRDS(iphc_file)$series_ABCD_full$ser_longest
discard_cpue <- read_csv(discard_cpue_file)
stitched_syn <- readRDS(stitched_syn_file)

dat <- readRDS(file.path(drs$nongit_dir, "data",
                         "arrowtooth-flounder-aug11-2022.rds"))

# Remove 2014 WCHG index point
wchg_2014_row <- 
  dat$survey_index$survey_abbrev == "SYN WCHG" & dat$survey_index$year == 2014
if(any(wchg_2014_row)){
  dat$survey_index <- dat$survey_index[-which(wchg_2014_row), ]
}

# These must be removed for call to add_extra_indices()
survey_index <- dat$survey_index %>% 
  select(-species_common_name, -species_science_name)
survey_index <- add_extra_indices(survey_index, 
                                  iphc = iphc,
                                  discard_cpue = discard_cpue,
                                  stitched_syn = stitched_syn)
# Survey index for geostat
geo_files <- dir(file.path(drs$nongit_dir, "survey-geostat"),
                 full.names = TRUE,
                 pattern = "^i-arrowtooth.*\\.rds$")
ind_geo <- purrr::map_dfr(geo_files, readRDS)
survey_index_geo <- ind_geo |>  filter(model == "no-depth") |> as_tibble()
survey_index_geo <- survey_index_geo |>
  rename(biomass = est,
         lowerci = lwr,
         upperci = upr,
         re = se,
         survey_abbrev = surveys) |>
  mutate(num_sets = NA,
         num_pos_sets = NA,
         survey_series_id = NA,
         survey_series_desc = "") |>
  select(-c(log_est, species, survey, ssids, ssid_string,
            family, anisotropy, spatiotemporal, share_range,
            model, max_grad)) |>
  select(year, biomass, lowerci, upperci,
         re, num_sets, num_pos_sets,
         survey_series_id, survey_abbrev, survey_series_desc) |>
  add_extra_indices(discard_cpue = discard_cpue)
# Add HS MSA survey so plot will work
hs_multi <- survey_index |> filter(survey_abbrev == "OTHER HS MSA")
survey_index_geo <- survey_index_geo |>
  bind_rows(hs_multi)

# Areas 3CD and 5ABCDE only 
major_areas <- c("03","04", "05", "06", "07", "08", "09")
tidy_areas <- c("3[CD]+", "5[ABCDE]+")
survey_sets <- dat$survey_sets |> 
  filter(major_stat_area_code %in% major_areas)
survey_samples <- dat$survey_samples |> 
  filter(major_stat_area_code %in% major_areas)
survey_samples_syn <- survey_samples |> 
  filter(survey_abbrev %in% c("SYN QCS",
                              "SYN HS",
                              "SYN WCVI",
                              "SYN WCHG"))
commercial_samples <- dat$commercial_samples |> 
  filter(major_stat_area_code %in% major_areas)
comm_ft <- extract_fleet_samples(commercial_samples)
comm_ss <- extract_fleet_samples(commercial_samples, include = FALSE)

# Aggregated commercial catch
month_start <- 2
day_start <- 21
dat$catch <- dat$catch |> filter(year < 2022)
catch <- tidy_catch(dat$catch,
                    areas = tidy_areas,
                    month_fishing_starts = month_start,
                    day_fishing_starts = day_start)
# Catch by fleet
catch_ft <- extract_fleet_catch(dat$catch) |> 
  tidy_catch(areas = tidy_areas,
             month_fishing_starts = month_start,
             day_fishing_starts = day_start)

catch_ss <- extract_fleet_catch(dat$catch, include = FALSE) |> 
  tidy_catch(areas = tidy_areas,
             month_fishing_starts = month_start,
             day_fishing_starts = day_start)

cpue_spatial <- dat$cpue_spatial
cpue_spatial_ll <- dat$cpue_spatial_ll
age_precision <- dat$age_precision

theme_set(gfiscam_theme())

# Gear names are set in the data file for each model
gear_names <- models$base_model[[1]]$dat$gear_names
if(fr()){
  # Translate all gear names to French
  # Note 'Shoreside' is the same in both languages 
  gear_names_fr <- map_chr(gear_names, ~{
    if(.x == "HS Multispecies Assemblage"){
      return("HS Assemblage multi-espÃ¨ces")
    }
    if(grepl("Synoptic", .x)){
      j <- str_split(.x, " ")[[1]]
      paste(j[1], tr(j[2]))
    }else{
      tr(.x)
    }
  })
  
  models$base_model <- 
    replace_gear_names(models$base_model,
                       old_gear_names = gear_names,
                       new_gear_names = gear_names_fr)
  models$bridge_grps[[1]] <- 
    replace_gear_names(models$bridge_grps[[1]],
                       old_gear_names = gear_names,
                       new_gear_names = gear_names_fr)
  models$bridge_grps[[2]] <- 
    replace_gear_names(models$bridge_grps[[2]],
                       old_gear_names = gear_names,
                       new_gear_names = gear_names_fr)
}

base_model <- models$base_model[[1]]

base_all_gears <- gear_lu_table(base_model, "all")
base_age_gears <- gear_lu_table(base_model, "age")
base_index_gears <- gear_lu_table(base_model, "index")
base_fleet_gears <- gear_lu_table(base_model, "fleet")

mcmc_chain_length <- 10000000
mcmc_num_samples <- 2000
mcmc_sample_freq <- mcmc_chain_length / mcmc_num_samples
mcmc_burn_in <- 1000
mcmc_actual_samples <- mcmc_num_samples - mcmc_burn_in

qcs <- "Queen Charlotte Sound Synoptic Survey"
hsmas <- "Hecate Strait Multispecies Assemblage Survey"
hss <- "Hecate Strait Synoptic Survey"
wcvis <- "West Coast Vancouver Island Synoptic Survey"
wchgs <- "West Coast Haida Gwaii Synoptic Survey"
dcpue <- "Discard CPUE Index"

la <- "2015 assessment"
# tv_block1 <- paste0(unique(filter(base_model$mcmccalcs$selest_quants,
#                                   gear == "QCS Synoptic", block == 1)$start_year),
#                     "--", 
#                     unique(filter(base_model$mcmccalcs$selest_quants,
#                                   gear == "QCS Synoptic", block == 1)$end_year))
# tv_block2 <- paste0(unique(filter(base_model$mcmccalcs$selest_quants,
#                                   gear == "QCS Synoptic", block == 2)$start_year),
#                     "--", 
#                     unique(filter(base_model$mcmccalcs$selest_quants,
#                                   gear == "QCS Synoptic", block == 2)$end_year))

# Text for selectivity block year ranges
# qcs_tv_yr_start <- base_model$ctl$start.yr.time.block[3, ]
# qcs_tv_yr_start[1] <- base_model$dat$start.yr
# qcs_tv_yr_end <- c(qcs_tv_yr_start[2:length(qcs_tv_yr_start)] - 1,
#                    base_model$dat$end.yr)
# if(length(qcs_tv_yr_start) == 2){
#   qcs_sel_ranges <- paste(paste0(qcs_tv_yr_start, "-", qcs_tv_yr_end),
#                           collapse = " and ")
# }else{
#   qcs_sel_ranges <- paste0(qcs_tv_yr_start, "-", qcs_tv_yr_end)
#   tmp <- qcs_sel_ranges[length(qcs_sel_ranges)]
#   qcs_sel_ranges <- paste(qcs_sel_ranges[-length(qcs_sel_ranges)],
#                           collapse = ", ")
#   qcs_sel_ranges <- paste0(qcs_sel_ranges, ", and ", tmp)
# }

# Number of parameters estimated (from PAR file)
num_params <- get_num_params_est(base_model)

# Catch table
ct <- as_tibble(base_model$dat$catch)
ct_start_yr <- min(ct$year)
ct_end_yr <- max(ct$year)

# Reference points (table values)
ref_pts <- as_tibble(base_model$mcmccalcs$params_quants)

# Projected biomass
end_yr <- base_model$dat$end.yr
assess_yr <- end_yr + 1
proj_yr <- assess_yr + 1
sbt_quants <- as_tibble(base_model$mcmccalcs$sbt_quants)
proj_bio <- sbt_quants[, as.character(assess_yr)] |> pull()

# Fishing mortality
f_max_by_gear <- map_dbl(base_model$mcmccalcs$ft_quants, ~{
  max(.x[2,])
})
f_max <- max(f_max_by_gear)
which_f_max <- which(f_max == f_max_by_gear)
which_f_max_gear <- base_model$dat$fleet_gear_names[which_f_max]
which_f_max_yr <- names(which(base_model$mcmccalcs$ft_quants[[which_f_max]][2, ] == f_max))

f_ci <- base_model$mcmccalcs$ft_quants[[which_f_max]][, base_model$mcmccalcs$ft_quants[[which_f_max]][2, ] == f_max]

# Relative spawning biomass
depl_end <- as_tibble(base_model$mcmccalcs$depl_quants) |>
  select(!!sym(as.character(assess_yr))) |> 
  pull()

# Decision table values - B_2023 < B_2022
table_dec <- table_decisions(base_model, ret_df = TRUE, digits = 3)
probs_catch_0 <- table_dec |> filter(tac == 0) |> unlist()
probs_catch_10 <- table_dec |> filter(tac == 10) |> unlist()
probs_catch_50 <- table_dec |> filter(tac == 50) |> unlist()
prob_proj_less_assess_0 <- probs_catch_0[length(probs_catch_0)]
prob_proj_less_assess_10 <- probs_catch_10[length(probs_catch_10)]
prob_proj_less_assess_50 <- probs_catch_50[length(probs_catch_50)]

probs_proj_less_assess <- table_dec[, ncol(table_dec)] |>
  pull() |> 
  as.numeric()
which_prob_less_50_50 <- which(probs_proj_less_assess < 0.5)
which_prob_less_50_50 <- which_prob_less_50_50[length(which_prob_less_50_50)]
prob_less_50_50 <- table_dec[which_prob_less_50_50, ]
prob_greater_50_50 <- table_dec[which_prob_less_50_50 + 1, ]

val_less_50_50 <- pull(prob_less_50_50[, ncol(prob_less_50_50)])

# Decision table values - B_2023 < 0.4B0
below_04bo <- table_dec |> 
  select(paste0(proj_yr, "_04bo")) |> 
  pull() |> 
  as.numeric()
range_below_04bo <- c(min(below_04bo), max(below_04bo))

# Decision table values - B_2023 < 0.2B0
below_02bo <- table_dec |> 
  select(paste0(proj_yr, "_02bo")) |> 
  pull() |> 
  as.numeric()
range_below_02bo <- c(min(below_02bo), max(below_02bo))
which_prob_greater_50_50_02bo <- which(below_02bo > 0.5)[1]
prob_greater_50_50_02bo <- below_02bo[which_prob_greater_50_50_02bo]
row_greater_50_50_02bo <- table_dec[which_prob_greater_50_50_02bo, ]

# Decision table values - B_2023 < 0.8BMSY
# below_08bmsy <- table_dec |> 
#   select(paste0(proj_yr, "_08bmsy")) |> 
#   pull() |> 
#   as.numeric()
# range_below_08bmsy <- c(min(below_08bmsy), max(below_08bmsy))

# Decision table values - B_2023 < 0.4BMSY
# below_04bmsy <- table_dec |> 
#   select(paste0(proj_yr, "_04bmsy")) |> 
#   pull() |> 
#   as.numeric()
#range_below_04bmsy <- c(min(below_04bmsy), max(below_04bmsy))
```

```{r biological-params}

find_length_outliers <- function(xx) {
  yy <- stats::pnorm(xx,
    mean = mean(xx, na.rm = TRUE),
    sd = stats::sd(xx, na.rm = TRUE), log.p = TRUE
  )
  zz <- stats::qnorm(yy, log.p = TRUE)
  out <- zz[zz > 4 & !is.na(zz)]
  if (length(out) > 1L) {
    return(xx[which(zz > 4)])
  } else {
    return(numeric(0))
  }
}

length_samples_survey <- filter(
  dat$survey_samples,
  !length %in% find_length_outliers(dat$survey_samples$length)
)

length_samples_ft <- filter(
  comm_ft,
  !length %in% find_length_outliers(comm_ft$length)
)

length_samples_ss <- filter(
  comm_ss,
  !length %in% find_length_outliers(comm_ss$length)
)

all_length_samples <- bind_rows(length_samples_survey, length_samples_ft, length_samples_ss)

all_age_samples <- bind_rows(dat$survey_samples, comm_ft, comm_ss) %>%
  filter(!is.na(age) & age < 40)
# it seems there's one extreme outlier... 50 y, also size and sex wouldn't make sense so definite error

# TODO: should the reported values (and coastwide plot) be for just from the 4 trawl surveys combined? Doesn't seem to fit as well if commercial samples added. 
#vb_m <- fit_vb(dat$survey_samples %>% filter(survey_series_id %in% c(1, 3, 4, 16)), 
#               sex = "male", method = "tmb", too_high_quantile = 1)

#vb_f <- fit_vb(dat$survey_samples %>% filter(survey_series_id %in% c(1, 3, 4, 16)), 
#               sex = "female", method = "tmb", too_high_quantile = 1)

#mat_fit <- fit_mat_ogive(dat$survey_samples %>% filter(survey_series_id %in% c(1, 3, 4, 16)), 
#                         type = "age", sample_id_re = TRUE, year_re = FALSE)
#                     
# Use function from this package as it is (very) slightly different than what 
# fit_mat_ogive() returns, and is what is input into the model
mat_fit <- export_mat_lw_age(dat$survey_samples, write_file = FALSE)
# TODO: what random effects wanted? If year, than params are saved as mat_fit$mat_perc$mean$f.mean.p0.5 and mat_fit$mat_perc$mean$m.mean.p0.5 instead of mat_fit$mat_perc$f.p0.5 and mat_fit$mat_perc$m.p0.5. I assume fig:fig-mat should also be made to match 

# Natural mortality values in the control file

param_ctl_table <- models$bridge_grps[[3]][[2]]$ctl$params |> as_tibble(rownames = "param")
male_m_ctl <- exp(param_ctl_table |> filter(param == "log_m_male") |> pull(ival))
female_m_ctl <- exp(param_ctl_table |> filter(param == "log_m_female") |> pull(ival))
```

```{r proportion-female}

if(!exists("data_dir")){
  stop("`data_dir` does not exist. If running from command line, ",
       "source('index.Rmd') to set up all project variables", call. = FALSE)
}

prop_female_fn <- file.path(data_dir, "prop_female_output.rds")
if(file.exists(prop_female_fn)){
  prop_female_lst <- readRDS(prop_female_fn)
}else{
  comm_prop <- props_comm(dat$commercial_samples)
  surv_prop <- props_surv(surv_series = c(1, 3, 4, 16),
                          surv_series_names = c("qcsss", "hsss", "wcviss", "wchgss"),
                          surv_samples = dat$survey_samples,
                          surv_sets = dat$survey_sets)
  prop_female_lst <- list(comm_prop, surv_prop)
  saveRDS(prop_female_lst, prop_female_fn)
}

prop_female_table <- table_prop_female(prop_female_lst, return_df = TRUE)
total_prop_female <- f(tail(prop_female_table, 1)[-1] |>
                         unlist() |>
                         as.numeric() |>
                         mean(),
                       2)
```

```{r model-param-value-calcs}

base_sbo <- get_parvals(base_model, "sbo")
base_bo <- get_parvals(base_model, "bo")
base_sbt <- get_parvals(base_model, "sbt")
base_depl <- get_parvals(base_model, "depl", digits = 2)
base_m_male <- get_parvals(base_model, "m_male", digits = 2)
base_m_female <- get_parvals(base_model, "m_female", digits = 2)
base_h <- get_parvals(base_model, "h", digits = 2)

bvals <- get_group_parvals(models$bridge_grps)
svals <- get_group_parvals(models$sens_grps)
# Now, to get the b0 median for the first sensitivity model in the third model group:
# Note you ave to skip the first one in each group because it is the base model
# svals[[3]][[2]]$bo[1]
# b0 CI range:
# svals[[3]][[2]]$bo[2]
# sbt median:
# svals[[3]][[2]]$sbt[1]
# sbt CI range:
# svals[[3]][[2]]$sbt[2]
# sbt end year:
# svals[[3]][[2]]$sbt[3

# Extract parameter values from the table found in the control file
#
# @param model The iSCAM model
# @param param The parameter name (row)
# @param value The value (column)
# @param digits The number of decimal points to return
#
# @return The value or row
# @export
get_ctl_params <- function(model, param = NULL, value = NULL, ...){
  inp_params <- as_tibble(rownames_to_column(as.data.frame(model$ctl$params),
                                             var = "param"))

  if(!is.null(param)){
    inp_params <- filter(inp_params, param == !!param)
  }
  if(!is.null(value)){
    return(pull(inp_params, value))
  }
  inp_params
}

get_param_est <- function(model, param = NULL, est_digits = 2, ...){
  if(is.null(param)){
    stop("Must provode `param` name", call. = FALSE)
  }
  
  if(param == "log_m_female"){
    param ="m_sex1"
  }
  if(param == "log_m_male"){
    param ="m_sex2"
  }
  raw <- as_tibble(model$mcmccalcs$params_quants)[[param]]
  paste0(f(raw[2], est_digits), " (", f(raw[1], est_digits), "--", f(raw[3], est_digits), ")")
}

get_param_vals <- function(model, param, est = TRUE, ...){
  out <- NULL
  out$init <- get_ctl_params(model, param, "ival", ...)
  out$p1 <- get_ctl_params(model, param, "p1", ...)
  out$p2 <- get_ctl_params(model, param, "p2", ...)
  if(est){
    out$est <- get_param_est(model, param, ...)
  }
  out
}

base_vartheta <- get_param_vals(base_model, "vartheta", est = FALSE, digits = 5)
base_rho <- get_param_vals(base_model, "rho", est = FALSE, digits = 5)
base_sig_tau <- calc_sig_tau(get_param_vals(base_model, "rho", est = FALSE)$init,
                             get_param_vals(base_model, "vartheta", est = FALSE)$init)
base_sig <- f(base_sig_tau[1], 1)
base_tau <- f(base_sig_tau[2], 1)

base_h <- get_param_vals(base_model, "h")
base_h_prior1 <- calc_beta_mean_cv(base_h$p1, base_h$p2)[1]
base_h_prior2 <- calc_beta_mean_cv(base_h$p1, base_h$p2)[2]
base_h_prior_params <- paste(f(base_h_prior1, 2),
                             ",",
                             f(base_h_prior2, 2))
base_m_female <- get_param_vals(base_model, "log_m_female")
base_m_male <- get_param_vals(base_model, "log_m_male")

sens_1_2_vartheta <- get_param_vals(models$sens_grps[[1]][[2]], "vartheta")
sens_1_2_rho <- get_param_vals(models$sens_grps[[1]][[2]], "rho", est = FALSE)
sens_1_2_sig_tau <- calc_sig_tau(get_param_vals(models$sens_grps[[1]][[2]],
                                                           "rho", est = FALSE)$init,
                                 get_param_vals(models$sens_grps[[1]][[2]],
                                                           "vartheta")$init)
sens_1_2_sig <- f(sens_1_2_sig_tau[1], 3)
sens_1_2_tau <- f(sens_1_2_sig_tau[2], 1)
sens_1_2_h <- get_param_vals(models$sens_grps[[1]][[2]], "h")
sens_1_2_sbo <- get_param_vals(models$sens_grps[[1]][[2]], "sbo")

sens_1_3_vartheta <- get_param_vals(models$sens_grps[[1]][[3]], "vartheta")
sens_1_3_rho <- get_param_vals(models$sens_grps[[1]][[3]], "rho", est = FALSE)
sens_1_3_sig_tau <- calc_sig_tau(get_param_vals(models$sens_grps[[1]][[3]],
                                                           "rho", est = FALSE)$init,
                                 get_param_vals(models$sens_grps[[1]][[3]],
                                                           "vartheta")$init)
sens_1_3_sig <- f(sens_1_3_sig_tau[1], 1)
sens_1_3_tau <- f(sens_1_3_sig_tau[2], 1)
sens_1_3_sbo <- get_param_vals(models$sens_grps[[1]][[3]], "sbo")


sens_1_4_vartheta <- get_param_vals(models$sens_grps[[1]][[4]], "vartheta")
sens_1_4_rho <- get_param_vals(models$sens_grps[[1]][[4]], "rho", est = FALSE)
sens_1_4_sig_tau <- calc_sig_tau(get_param_vals(models$sens_grps[[1]][[4]],
                                                           "rho", est = FALSE)$init,
                                 get_param_vals(models$sens_grps[[1]][[4]],
                                                           "vartheta")$init)
sens_1_4_sbo <- get_param_vals(models$sens_grps[[1]][[4]], "sbo")

sens_1_4_sig <- f(sens_1_4_sig_tau[1], 1)
sens_1_4_tau <- f(sens_1_4_sig_tau[2], 1)

sens_1_5_h <- get_param_vals(models$sens_grps[[1]][[5]], "h")
sens_1_5_h_prior1 <- calc_beta_mean_cv(sens_1_5_h$p1, sens_1_5_h$p2)[1]
sens_1_5_h_prior2 <- calc_beta_mean_cv(sens_1_5_h$p1, sens_1_5_h$p2)[2]
sens_1_5_h_prior_params <- paste(f(sens_1_5_h_prior1, 2),
                             ",",
                             f(sens_1_5_h_prior2, 2))

sens_2_2_m_female <- get_param_vals(models$sens_grps[[2]][[2]], "log_m_female")
sens_2_3_m_female <- get_param_vals(models$sens_grps[[2]][[3]], "log_m_female")
sens_2_4_m_male <- get_param_vals(models$sens_grps[[2]][[4]], "log_m_male")
sens_2_5_m_male <- get_param_vals(models$sens_grps[[2]][[5]], "log_m_male")

# qk priors and estimates
base_qk_inp_params <- base_model$ctl$surv.q
base_qk_mean <- exp(base_qk_inp_params[rownames(base_qk_inp_params) == "priormeanlog"])[1]
base_qk_sd <- base_qk_inp_params[rownames(base_qk_inp_params) == "priorsd"][1]

sens_qk_inp_params <- models$sens_grps[[3]][[2]]$ctl$surv.q
sens_qk_mean <- exp(sens_qk_inp_params[rownames(sens_qk_inp_params) == "priormeanlog"])[1]
sens_qk_sd <- sens_qk_inp_params[rownames(sens_qk_inp_params) == "priorsd"][1]

sens_qkp_inp_params <- models$sens_grps[[3]][[3]]$ctl$surv.q
sens_qkp_mean <- exp(sens_qkp_inp_params[rownames(sens_qkp_inp_params) == "priormeanlog"])[1]
sens_qkp_sd <- sens_qkp_inp_params[rownames(sens_qkp_inp_params) == "priorsd"][1]

sens_3_2_selex_f_qcs <- filter(models$sens_grps[[3]][[2]]$mcmccalcs$selest_quants, gear == "QCS Synoptic", sex == 2)$a_hat
sens_3_2_selex_f_qcs_mean_ci <- paste0(f(sens_3_2_selex_f_qcs[2], 1),
                                       " (",
                                       f(sens_3_2_selex_f_qcs[1], 1),
                                       "--",
                                       f(sens_3_2_selex_f_qcs[3], 1),
                                       ")")

# This is a hard coded value in the abstract (percentage of posteriors below the 0.2B0 LRP)
prob_below_02_sbo_2022 <- sum(unlist(base_model$mcmccalcs$depl[, ncol(base_model$mcmccalcs$depl)]) < 0.2) / 
  nrow(base_model$mcmccalcs) * 100

split_sex_model_sel <- models$bridge_grps[[2]][[4]]$mcmccalcs$selest_quants |> filter(gear == "QCS Synoptic", sex == 2)
split_sex_model_sel_ahat <- paste0(f(split_sex_model_sel$a_hat[2]), " (", 
                                   f(split_sex_model_sel$a_hat[1]), "--",
                                   f(split_sex_model_sel$a_hat[3]), ")")
split_sex_model_sel_ghat <- paste0(f(split_sex_model_sel$g_hat[2]), " (", 
                                   f(split_sex_model_sel$g_hat[1]), "--",
                                   f(split_sex_model_sel$g_hat[3]), ")")

theme_set(theme_pbs())
```

<!-- ---------------------------------------------------------------------- -->
```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#1c5253",
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Montserrat", "300", "300i"),
  code_font_google   = google_font("Fira Mono")
)
```

---
class: center
### Introduction

.left[
**`r sp`**
- are a flatfish that occurs in the offshore waters of `r bc`;
- mostly feed on Capelin, Euphausiids, Walleye Pollock, Pandalid shrimp, Herring, and other forage fish;
- are prey for mostly Pacific Cod, Pacific Halibut, and Steller sea lions; for juveniles, adult `r sp` and Walleye Pollock;
- are primarily caught by bottom trawl fishery, and sometimes by hook and line in the Halibut fishery;
- must be frozen shortly after catching due to proteolysis of the flesh;
- seasonal vertical migration to deeper water in winter, shallower in summer; and
- spawn and hatch in deeper water (>350m), in winter.

**The `r la` model**
- included data from 1996-2014 and
- was done with a model which was female only and had a single commercial trawl fleet.
- Link to the .link-style1[[Research document](https://www.dfo-mpo.gc.ca/csas-sccs/Publications/ResDocs-DocRech/2017/2017_025-eng.html)]

**The 2021 assessment model**
- includes data from 1996-2021;
- includes 3 synoptic surveys (QCS, HS, and WCVI) and
- is split by sex, and has two commercial trawl fleets (Freezer trawlers and Shoreside).
]

---
class: center
### Management

.left[
**`r sp`**
- are managed as a coastwide stock;
- had no limits on catch prior to 2006;
- had a TAC of 15,000 t in place from 2006-2017;
- had the TAC increased to 17,500 t in 2017 and
- had the TAC decreased to 14,000 t in 2019.

On Jan. 30, 2020, late changes to the Integrated Fisheries Management Plan (IFMP) to address declining abundance in the synoptic surveys were recommended. These changes included:
- reducing 2020/2021 TAC from 14,000 t to 5,000 t;
- reducing 2019/2020 carryover allowance from 30% to 10%;
- reducing the amount of temporary quota a license can hold from 16% to 8% of TAC and
- implementing new spatial closures from Nov. 1 to Mar. 31 to limit harvesting of spawning aggregations.

.link-style1[[IFMP for Groundfish](https://www.pac.dfo-mpo.gc.ca/fm-gp/mplans/ground-fond-ifmp-pgip-sm-eng.html)]
]

---
class: center
### Management Areas and catch
```{r management-areas, out.width = 900}
plot_catch_spatial(dat$catch_spatial, 
                   show_majorbound = TRUE, 
                   # major_labels = labels,
                   start_year = base_model$dat$start.yr,
                   fill_scale = scale_fill_viridis_c(trans = "log10", option = "D"),
                   colour_scale = scale_colour_viridis_c(trans = "log10", option = "D"))

```

---
class: center
### Catch data

.left[
**Catch for `r sp`**
- had no discard reporting prior to 1996, when observers were introduced. Entire tows were often discarded without report;
- continued to be discarded at sea in great numbers until the arrival of freezer trawlers in the mid 2000's, which could freeze their catch at sea and avoid proteolysis;
- had large declines recently (2020-2021) which was due to TAC reductions
- was dominated by Freezer trawlers in the last decade.

**Notes on catch**
- The commercial fishing year for `r sp` starts on Feb 21 and ends on Feb 20. All yearly catch data in this assessment were aggregated in this way.

- Historical catch reconstruction was not attempted due to the unreported discards at sea prior to 1996.

- The large spike in 2005 catch was from a test fishery that took place in area 5D. There was an immediate drop the next year due to lack of profitability of the fishery, likely due to proteolysis and lack of freezers at sea.
]

---
class: center
### Catch by area
```{r catch-by-area, out.width = 900}
yrs <- sort(unique(catch$year))
plot_catch(catch, french = fr(), xlim = c(min(yrs), max(yrs))) +
  scale_x_continuous(yrs, breaks = seq(min(yrs), yrs[length(yrs)], by = 2)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 0.55, vjust = 0.5))

```

---
class: center
### Catch by fleet

```{r catch-by-fleet, out.width = 900}
yrs <- sort(unique(catch$year))
plot_catch_fleet(list(catch_ft, catch_ss),
                 base_model$dat$fleet_gear_names,
                 french = fr(),
                 xlim = c(min(yrs), max(yrs))) +
  scale_x_continuous(yrs, breaks = seq(min(yrs), yrs[length(yrs)], by = 2)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 0.55, vjust = 0.5))

```

---
class: center
### Length data

```{r length-data, out.width = 900}

bin_width1 <- diff(quantile(length_samples_survey$length,
                            na.rm = TRUE,
                            probs = c(0, 1))) / 20

bin_width2 <- diff(quantile(length_samples_ft$length,
                            na.rm = TRUE, probs = c(0, 1))) / 20

bin_width3 <- diff(quantile(length_samples_ss$length,
                            na.rm = TRUE, probs = c(0, 1))) / 20

bin_width <- mean(c(bin_width1, bin_width2, bin_width3),
                  na.rm = TRUE)

ss <- tidy_lengths_weighted(length_samples_survey,
                            dat_survey_sets = dat$survey_sets,
                            bin_size = bin_width,
                            sample_type = "survey")

sf <- length_samples_ft |> 
  mutate(sex = 2) |>  # fake all sex as female for commercial samples; often not sexed
  tidy_lengths_weighted(dat_catch = dat$catch,
                        bin_size = bin_width,
                        sample_type = "commercial",
                        spp_cat_code = 1) |> 
  mutate(survey_abbrev = "Freezer Trawlers")

sc <- length_samples_ss |> 
  mutate(sex = 2) %>% # fake all sex as female for commercial samples; often not sexed
  tidy_lengths_weighted(dat_catch = dat$catch,
                        bin_size = bin_width,
                        sample_type = "commercial",
                        spp_cat_code = 1) |> 
  mutate(survey_abbrev = "Shoreside")

min_total <- 20

sc_old <- filter(sc, year < 1995) # are we interested in length frequencies pre-1980?
sc <- filter(sc, year > 1995)
sb <- suppressWarnings(bind_rows(ss, sc, sf))
sb$survey_abbrev <- factor(sb$survey_abbrev,
                           levels = c("SYN WCHG",
                                      "SYN HS",
                                      "SYN QCS",
                                      "SYN WCVI",
                                      tr("Freezer Trawlers"),
                                      tr("Shoreside")))

sb$year <- factor(sb$year, levels = seq(1996, 2021))

g_lengths <- plot_lengths(sb,
                          survey_cols = setNames(c("#FC8D62",
                                                   "#FC8D62",
                                                   "#FC8D62",
                                                   "#FC8D62",
                                                   "#000000",
                                                   "#000000"),
                                                 c("SYN WCHG",
                                                   "SYN HS",
                                                   "SYN QCS",
                                                   "SYN WCVI",
                                                   tr("Freezer Trawlers"),
                                                   tr("Shoreside"))),
                          bin_size = bin_width,
                          min_total = min_total) +
  # scale_x_continuous(breaks = x_breaks, labels = x_labels) +
  guides(colour = "none", fill = "none") +
  ggtitle("") +
  xlab(paste(tr("Length"), "(cm)")) +
  ylab(tr("Relative length frequency")) +
  theme(strip.text.y.right = element_text(angle = 0))

g_lengths
```

---
class: center
### Age data

```{r age-data, out.width = 900}

ss <- tidy_ages_weighted(dat$survey_samples,
                         dat_survey_sets = dat$survey_sets,
                         sample_type = "survey")

ss$survey_abbrev <- factor(ss$survey_abbrev)
s_ages <- plot_ages(ss,
                    survey_cols = stats::setNames(
                      c("#FC8D62", "#FC8D62", "#FC8D62", "#FC8D62"),
                      c("SYN WCHG", "SYN HS", "SYN QCS", "SYN WCVI"))) +
  facet_wrap(~survey_abbrev, nrow = 1, scales = "free_x") +
  guides(fill = "none", colour = "none") +
  theme(plot.title = element_blank(),
        axis.title = element_blank())

sc <- tidy_ages_weighted(comm_ss,
                         dat_catch = dat$catch,
                         sample_type = "commercial") |> 
  mutate(survey_abbrev = "Shoreside")

sf <- tidy_ages_weighted(comm_ft,
                         dat_catch = dat$catch,
                         sample_type = "commercial") |>
  mutate(survey_abbrev = "Freezer Trawlers")

sb <- suppressWarnings(bind_rows(sc, sf))

sb$survey_abbrev <- factor(sb$survey_abbrev)

c_ages <- plot_ages(sb,
                    survey_cols = setNames(c("black", "black"),
                                           c("Freezer Trawlers", "Shoreside"))) +
  guides(fill = "none", colour = "none") +
  theme(plot.title = element_blank(),
        axis.title = element_blank())

grid.arrange(s_ages,
             c_ages,
             nrow = 2,
             # heights = c(1.1,1),
             left = tr("Ages (years)"),
             bottom = tr("Year sampled"))
```

---
class: center
### Length/Weight fits by sex

```{r length-weight, out.width = 900}

if(!exists("data_dir")){
  stop("`data_dir` does not exist. If running from command line, ",
       "source('index.Rmd') to set up all project variables", call. = FALSE)
}
lw_fn <- file.path(data_dir, "fit_lw_output.rds")
if(file.exists(lw_fn)){
  lw_lst <- readRDS(lw_fn)  
}else{
  lw_lst <- list(
    fit_length_weight(filter(survey_samples, survey_abbrev %in% "SYN QCS"), sex = "female"),
    fit_length_weight(filter(survey_samples, survey_abbrev %in% "SYN QCS"), sex = "male"),
    fit_length_weight(filter(survey_samples, survey_abbrev %in% "SYN HS"), sex = "female"),
    fit_length_weight(filter(survey_samples, survey_abbrev %in% "SYN HS"), sex = "male"),
    fit_length_weight(filter(survey_samples, survey_abbrev %in% "SYN WCVI"), sex = "female"),
    fit_length_weight(filter(survey_samples, survey_abbrev %in% "SYN WCVI"), sex = "male"),
    fit_length_weight(survey_samples_syn, sex = "female"),
    fit_length_weight(survey_samples_syn, sex = "male"))
  saveRDS(lw_lst, lw_fn)
}
lw_title_lst <- list(
  tr("SYN QCS (5AB)"),
  tr("SYN HS (5CD)"),
  tr("SYN WCVI (3CD)"),
  tr("Coastwide"))

plot_lw_panels <- function(lw_f, lw_m){
  plot_length_weight(object_female = lw_f,
                     object_male = lw_m,
                     french = fr()) +
    guides(colour = "none", fill = "none", lty = "none") +
    
    # coord_cartesian(xlim = c(0, 85), ylim = c(0, 6.7)) +
    xlim(0, 85) +
    theme(axis.title = element_blank())
}

lw_plot_lst <- list(
  plot_lw_panels(lw_lst[[1]], lw_lst[[2]]) +
  ggtitle(lw_title_lst[[1]]),
  
  plot_lw_panels(lw_lst[[3]], lw_lst[[4]]) +
  ggtitle(lw_title_lst[[2]]),
  
  plot_lw_panels(lw_lst[[5]], lw_lst[[6]]) +
  ggtitle(lw_title_lst[[3]]),

  plot_lw_panels(lw_lst[[7]], lw_lst[[8]]) +
  ggtitle(lw_title_lst[[4]]))

grid.arrange(grobs = lw_plot_lst,
             ncol = 2,
             bottom = paste0(tr("Length"), " (cm)"),
             left = tr("Weight (kg)"))

```

---
class: center
### Length/Age fits

```{r vb-fits, out.width = 900}

if(!exists("data_dir")){
  stop("`data_dir` does not exist. If running from command line, ",
       "source('index.Rmd') to set up all project variables", call. = FALSE)
}
vb_fn <- file.path(data_dir, "fit_vb_output.rds")
if(file.exists(vb_fn)){
  vb_lst <- readRDS(vb_fn)  
}else{
  vb_lst <- list(
    fit_vb(filter(survey_samples, survey_abbrev %in% "SYN QCS")),
    fit_vb(filter(survey_samples, survey_abbrev %in% "SYN QCS"), sex = "male"),
    fit_vb(filter(survey_samples, survey_abbrev %in% "SYN HS")),
    fit_vb(filter(survey_samples, survey_abbrev %in% "SYN HS"), sex = "male"),
    fit_vb(filter(survey_samples, survey_abbrev %in% "SYN WCVI")),
    fit_vb(filter(survey_samples, survey_abbrev %in% "SYN WCVI"), sex = "male"),
    fit_vb(survey_samples_syn),
    fit_vb(survey_samples_syn, sex = "male"))
  saveRDS(vb_lst, vb_fn)
}
vb_title_lst <- list(
  tr("SYN QCS (5AB)"),
  tr("SYN HS (5CD)"),
  tr("SYN WCVI (3CD)"),
  tr("Coastwide"))

plot_vb_panels <- function(vb_f, vb_m){
  plot_vb(object_female = vb_f,
          object_male = vb_m,
          french = fr()) +
    guides(colour = "none", fill = "none", lty = "none") +
    theme(axis.title = element_blank()) +
    coord_cartesian(xlim = c(0, 25), ylim = c(0, 75))
}

vb_plot_lst <- list(
  plot_vb_panels(vb_lst[[1]], vb_lst[[2]]) +
  ggtitle(vb_title_lst[[1]]),
  
  plot_vb_panels(vb_lst[[3]], vb_lst[[4]]) +
  ggtitle(vb_title_lst[[2]]),
  
  plot_vb_panels(vb_lst[[5]], vb_lst[[6]]) +
  ggtitle(vb_title_lst[[3]]),

  plot_vb_panels(vb_lst[[7]], vb_lst[[8]]) +
  ggtitle(vb_title_lst[[4]]))

grid.arrange(grobs = vb_plot_lst,
             ncol = 2,
             left = paste0(tr("Length"), " (cm)"),
             bottom = tr("Age (years)"))
```

---
class: center
### Age and length-at maturity ogives

```{r mat-fits, out.width = 900}

mat_fn <- file.path(data_dir, "fit_mat_ogive_output.rds")
if(file.exists(mat_fn)){
  mat_lst <- readRDS(mat_fn)
}else{
  mat_lst <- list(
    fit_mat_ogive(filter(survey_samples, survey_abbrev %in% "SYN QCS")),
    fit_mat_ogive(filter(survey_samples, survey_abbrev %in% "SYN QCS"), type = "length"),
    fit_mat_ogive(filter(survey_samples, survey_abbrev %in% "SYN HS")),
    fit_mat_ogive(filter(survey_samples, survey_abbrev %in% "SYN HS"), type = "length"),
    fit_mat_ogive(filter(survey_samples, survey_abbrev %in% "SYN WCVI")),
    fit_mat_ogive(filter(survey_samples, survey_abbrev %in% "SYN WCVI"), type = "length"),
    fit_mat_ogive(survey_samples_syn),
    fit_mat_ogive(survey_samples_syn, type = "length"))
  saveRDS(mat_lst, mat_fn)
}
mat_title_lst <- list(
  tr("SYN QCS (5AB)"),
  "",
  tr("SYN HS (5CD)"),
  "",
  tr("SYN WCVI (3CD)"),
  "",
  tr("Coastwide synoptic trawl surveys"),
  "")

plot_mat_panels <- function(fit_obj){
  p <- plot_mat_ogive(fit_obj,
                      show_quant_text = FALSE) +
    guides(colour = "none", fill = "none", lty = "none") +
    ggplot2::guides(lty = "none", colour = "none") + 
    theme(axis.title.y = element_blank())
  p
}

ma_plot_lst <- list(
  plot_mat_panels(mat_lst[[1]]) +
  coord_cartesian(xlim = c(0, 18), ylim = c(0, 1)) +
  theme(axis.title = element_blank()) +
  ggtitle(mat_title_lst[[1]]),

  plot_mat_panels(mat_lst[[2]]) +
  coord_cartesian(xlim = c(0, 82), ylim = c(0, 1)) +
  theme(axis.title = element_blank()) +
  ggtitle(mat_title_lst[[2]]),

  plot_mat_panels(mat_lst[[3]]) +
  coord_cartesian(xlim = c(0, 18), ylim = c(0, 1)) +
  theme(axis.title = element_blank()) +
  ggtitle(mat_title_lst[[3]]),

  plot_mat_panels(mat_lst[[4]]) +
  coord_cartesian(xlim = c(0, 82), ylim = c(0, 1)) +
  theme(axis.title = element_blank()) +
  ggtitle(mat_title_lst[[4]]),

  plot_mat_panels(mat_lst[[5]]) +
  coord_cartesian(xlim = c(0, 18), ylim = c(0, 1)) +
  theme(axis.title = element_blank()) +
  ggtitle(mat_title_lst[[5]]),

  plot_mat_panels(mat_lst[[6]]) +
  coord_cartesian(xlim = c(0, 82), ylim = c(0, 1)) +
  theme(axis.title = element_blank()) +
  ggtitle(mat_title_lst[[6]]),

  plot_mat_panels(mat_lst[[7]]) +
  coord_cartesian(xlim = c(0, 18), ylim = c(0, 1)) +
  ggtitle(mat_title_lst[[7]]) +
  xlab(tr("Age (years)")),

  plot_mat_panels(mat_lst[[8]]) +
  coord_cartesian(xlim = c(0, 82), ylim = c(0, 1)) +
  ggtitle(mat_title_lst[[8]]) +
  xlab(paste0(tr("Length"), " (cm)")))

grid.arrange(grobs = ma_plot_lst,
             ncol = 2,
             left = paste0(tr("Probability mature")))
```

---
class: center
### Growth Parameters fit externally

```{r growth-params-table, results = "asis"}

# This is a necessary step when compiling a latex table in HTML!
tex2markdown <- function(texstring) {
  writeLines(text = texstring,
             con = myfile <- tempfile(fileext = ".tex"))
  texfile <- pandoc(input = myfile, format = "html")
  cat(readLines(texfile), sep = "\n")
  unlink(c(myfile, texfile))
}

tex_table <- table_growth_params(base_model,
                                 digits = 3,
                                 alpha_digits = 7,
                                 booktabs = FALSE,
                                 longtable = FALSE,
                                 repeat_header = FALSE,
                                 bold_header = FALSE,
                                 cap = "")
tex2markdown(tex_table)
```

---
class: center
### Proportion female

.left[
The proportion of females in the population was calculated for the four synoptic surveys and the commercial trawl (as a single fleet).
- The Gulf of Alaska and Bering Sea/Aleutian Islands assessments use <SPAN STYLE="font-size:18.0pt">0.7</SPAN> 

Data used for these calculations were filtered for:
- Sampled category
    - Unsorted
    - Discards
- Sample type
    - total catch
    - random
    - random from randomly assigned set
    - random from set after randomly assigned set
    - random from set requested by vessel master
- Gear codes
    - Bottom trawl
    - Unknown trawl
- Age data: 1996 through 2019
- Areas: 3CD and 5ABCDE
- Sex: males and females only, any null, unknown, or unsexed specimens were dropped
]

---
class: center
### Proportion female - Equations

.left[
- Observations from a single sample are likely to be correlated due to limited trawl area from a single tow.
- Trip samples are likely to be correlated due to vessel targeting practices.
- Time of year (for commercial trawl) may be have an effect due to vertical migration to deeper water in the fall/winter.

The total weight (from sum of catch for sampled catch) in each quarter of the year by sex:

<img class="fortypercsize" src="figures/equation_b_5_prop_female.jpg">

<img class="fortypercsize" src="figures/equation_b_7_prop_female.jpg">

The proportions female each year were calculated as:

<img class="fortypercsize" src="figures/equation_b_8_prop_female.jpg">
]

---
class: center
### Proportion female - summary

```{r prop-female-table-left, results = "asis"}
t1 <- table_prop_female(prop_female_lst,
                        digits = 2,
                        longtable = FALSE,
                        format = "html",
                        font_size = 14,
                        caption = "",
                        yrs = 1996:2007)
t2 <- table_prop_female(prop_female_lst,
                        digits = 2,
                        longtable = FALSE,
                        format = "html",
                        font_size = 14,
                        caption = "",
                        yrs = 2008:2019)
cat(c('<table><tr valign="top"><td>',
      t1,
      '</td><td>',
      t2,
      '</td><tr></table>'),
    sep = '')
```
.left[
The overall mean of the survey and the commercial fishery means is <SPAN STYLE="font-size:18.0pt">0.79</SPAN>

This was input into the ISCAM base model.
]
---
class: center
### Abundance Indices

.left[
Five fishery independent indices of abundance were fit in the base model:

- *`r qcs` (Age comps/estimated selectivity)*

- `r hsmas` (No age comps/fixed selectivity)

- *`r hss` (Age comps/estimated selectivity)*

- *`r wcvis` (Age comps/estimated selectivity)*

- `r dcpue` (No age comps/fixed selectivity)


All are in thousands of tonnes except the `r dcpue` which is in kg/hr.
]

---
class: center
### Abundance Indices - `r dcpue`
.left[
We generated an index of abundance from discard commercial trawl CPUE standardized for:
- depth;
- fishing locality (defined spatial regions);
- month;
- vessel and
- latitude.

**Data filtering:**
- include tows where 100% of caught `r sp` were discarded, to avoid tows targeting `r sp`;
- include vessels that have caught and discarded `r sp` in at least 100 tows from 1996-2021;
- those vessels have had at least five trips that recorded `r sp` for at least five years from 1996-2021.

**Standardization model predictors:**
- for depth, binned into 25m-wide bands;
- for latitude, binned into 0.1-degree-wide bands;
- limited both to include only bands that fell in 0.1% and 99.9% probability of positive observations;
- removed any that contained fewer than 0.1% of observations

TODO: Add the rest or make another presentation, See Appendix C for details.
]



---
class: center
### Abundance Indices - Fits

```{r index-fits-base, out.width = 900}
plot_index_mcmc(base_model,
                type = "fits",
                surv_index = survey_index,
                leg_loc = NULL,
                text_title_size = NULL)
```

---
class: center
### Abundance Indices - Residuals

```{r index-residuals-base, out.width = 900}
plot_index_mcmc(base_model,
                type = "resids",
                surv_index = survey_index,
                leg_loc = NULL,
                text_title_size = NULL)
```

---
class: center
### Age data
.left[
Age data were
- recorded using break-and-bake method where a whole tray of otoliths are baked and then individually broken and rings counted;

- chosen randomly across many vessels for the commercial trawl fishery;

- included for both commercial fleets and three synoptic surveys;

- input into the model as weighted proportions-at-age using the methods of Holt et. al (2016) and Grandin and Forrest (2017). This method is coded into the `weight_comps()` function located in the .link-style1[[gfplot R package](https://github.com/pbs-assess/gfplot)].

]

---
class: center
### Age fits/residuals - Freezer trawlers
.left-fig[
```{r age-fits-base-ft, out.width = "100%", fig.dim = c(4.8, 4.5)}
plot_age_fits_mcmc(base_model, gear = 1, text_title_size = NULL, angle_x_labels = TRUE)
```
]
.right-fig[
```{r age-resids-base-ft, out.width = "100%", fig.dim = c(4.8, 4.5)}
plot_age_resids_mcmc(base_model, gear = 1, text_title_size = NULL, leg_loc = c(0.95, 0.95))
```
]

---
class: center
### Age fits - Shoreside
.left-fig[
```{r age-fits-base-ss-1, out.width = "100%", fig.dim = c(4.8, 4.5)}
plot_age_fits_mcmc(base_model, gear = 2, yrs = 1996:2007, text_title_size = NULL, angle_x_labels = TRUE)
```
]
.right-fig[
```{r age-fits-base-ss-2, out.width = "100%", fig.dim = c(4.8, 4.5)}
plot_age_fits_mcmc(base_model, gear = 2, yrs = 2008:2021, text_title_size = NULL, angle_x_labels = TRUE)
```
]

---
class: center
### Age residuals - Shoreside

```{r age-resids-base-ss, out.width = 900}
plot_age_resids_mcmc(base_model, gear = 2, text_title_size = NULL, leg_loc = c(0.95, 0.95))
```

---
class: center
### Age fits/residuals - QCS Synoptic survey
.left-fig[
```{r age-fits-base-qcs, out.width = "100%", fig.dim = c(4.8, 4.5)}
plot_age_fits_mcmc(base_model, gear = 3, text_title_size = NULL, sample_size_y = 0.15, angle_x_labels = TRUE)
```
]
.right-fig[
```{r age-resids-base-qcs, out.width = "100%", fig.dim = c(4.8, 4.5)}
plot_age_resids_mcmc(base_model, gear = 3, text_title_size = NULL, leg_loc = c(0.95, 0.95))
```
]

---
class: center
### Age fits/residuals - HS Synoptic survey
.left-fig[
```{r age-fits-base-hss, out.width = "100%", fig.dim = c(4.8, 4.5)}
plot_age_fits_mcmc(base_model, gear = 4, text_title_size = NULL, sample_size_y = 0.15, angle_x_labels = TRUE)
```
]
.right-fig[
```{r age-resids-base-hss, out.width = "100%", fig.dim = c(4.8, 4.5)}
plot_age_resids_mcmc(base_model, gear = 4, text_title_size = NULL, leg_loc = c(0.95, 0.95))
```
]

---
class: center
### Age fits/residuals - WCVI Synoptic survey
.left-fig[
```{r age-fits-base-wcvi, out.width = "100%", fig.dim = c(4.8, 4.5)}
plot_age_fits_mcmc(base_model, gear = 5, text_title_size = NULL, sample_size_y = 0.15, angle_x_labels = TRUE)
```
]
.right-fig[
```{r age-resids-base-wcvi, out.width = "100%", fig.dim = c(4.8, 4.5)}
plot_age_resids_mcmc(base_model, gear = 5, text_title_size = NULL, leg_loc = c(0.95, 0.95))
```
]

---
class: center
### Selectivity estimates
.left[
Selectivities were estimated for the gears with age compositions; the two trawl fleets and the three synoptic surveys (not including WCHG).
- Maturities are shown on the plots (dashes lines) to show why the vulnerable biomass was estimated so small, the selectivities are almost all estimated to the right of the maturities, especially the males.
- Single blue lines represent fixed selectivities; both sexes were fixed the the same value.

```{r selex-base, out.width = "60%"}
plot_selex_mcmc(base_model, show_maturity = TRUE, leg_loc = "facet")
```
]

---
class: center
### Reference point estimates
.left[
- The $U_{MSY_2}$ posterior (Shoreside fleet) is all at or near 1, meaning the fishing mortality is unrealistically large.
- This implies that no amount of fishing would impact the stock, and is why the MSY-based reference points are extremely liberal.

```{r ref-points-base, out.width = "60%" }
plot_ref_points(base_model)
```
]
