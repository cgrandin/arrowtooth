---
title: "Arrowtooth Flounder (*Atheresthes stomias*) Stock Assessment for the West Coast of British Columbia in 2021"
french_title: "Évaluation du stock de la plie à dents de flèche (Atheresthes stomias) sur la côte ouest de la Colombie-Britannique en 2021 Colombie-Britannique en 2021"
author: |
  Chris J. Grandin^1^ and
  Sean C. Anderson^1^
author_list: "Grandin, C.J. and Anderson, S.C."
address: |
  ^1^Pacific Biological Station\
     Fisheries and Oceans Canada, 3190 Hammond Bay Road\
     Nanaimo, British Columbia, V9T 6N7, Canada
french_address: |
  ^1^Station bioslogique du Pacifique\
     Pêches et Océans Canada, 3190 Hammond Bay Road\
     Nanaimo, Colombie-Britannique, V9T 6N7, Canada\
  \smallskip
  ^2^Loin, très loin\
     Une autre galaxie
month: October
french_month: Octobre
year: 2021
report_number: nnn
region: Pacific Region
french_region: "Région du Pacifique"
isbn: "978-0-660-38322-4"
cat_no: "Fs70-6/2021-012E-PDF"
citation_other_language: "Grandin, C.J. et Anderson, S.C. Title Here (*Latin Species Name*). DFO Secr. can. de consult. sci. du MPO. Doc. de rech 2019/nnn. iv + 13 p."

abstract: |
  Arrowtooth Flounder (*Atheresthes stomias*, Turbot) are an important component of the bottom trawl fishery in British Columbia. They are managed as a coastwide stock, with a current TAC of 5,000 t and catch of 3,051 t in 2021. Prior to the introduction of freezer trawlers in the mid-2000s, most of the historical catch of Arrowtooth Flounder is understood to have been discarded at sea. This was largely due to proteolysis, which occurs in the muscle tissue of this species a short time after it is caught, making the flesh unpalatable.

  In the past decade, markets have been established for fillets that have been frozen at sea, and the freezer trawl fleet has taken an increasing proportion of the coastwide catch.

french_abstract: |
  La plie à dents de flèche (*Atheresthes stomias*, Turbot) est une composante importante de la pêche au chalut de fond en Colombie-Britannique. Elle est gérée comme un stock de toute la côte, avec un TAC de 4 000 t et des prises de 10 679 t en 2014. Avant l'introduction des chalutiers congélateurs au milieu des années 2000, on comprend que la plupart des prises historiques de la limande à dents de flèche étaient rejetées en mer. Cela était dû en grande partie à la protéolyse, qui se produit dans le tissu musculaire de cette espèce peu de temps après la capture, rendant la chair peu appétissante.
  
  Au cours de la dernière décennie, des marchés ont été créés pour les filets qui ont été congelés en mer, et la flotte de chalutiers congélateurs a pris une proportion croissante des prises côtières. Traduit avec www.DeepL.com/Translator (version gratuite)

header: "Draft working paper --- Do not cite or circulate" # or "" to omit
output:
 csasdown::resdoc_pdf:
   # build_rds is a toggle to re-build all the RDS files for the models
   build_rds: false
   keep_md: true
   french: false
   # copy_sty is a toggle to copy the style file from the csasdown package every time you compile
   # the document. If false, any changes you have made to the style file in your project
   # will remain between compilations. If true, your changes will be lost when you compile
   copy_sty: true
   # line_nums is a toggle to show line numbers on the left side of the page. 
   line_nums: true
   # line_nums_mod represents showing every Nth line if line_nums is true
   line_nums_mod: 1
   # lot_lof is a toggle to show/not show the lists of tables and figures at the
   # beginning of the document
   lot_lof: false
   # draft_watermark is a toggle to show/not show a DRAFT watermark across every page
   draft_watermark: false
   # include_section_nums, if true includes section numbering in the document body,
   # if false, no numbering in the document body but the TOC will still show numbering
   include_section_nums: true
   # highlight is the theme to use for code output. Must be one of the list given by:
   # pandoc --list-highlight-styles
   # which are:
   # pygments, tango, espresso, zenburn, kate, monochrome, breezedark, haddock
   # or the name of a custom *.latex file which is most easily made by copying one from 
   # the csasdown library 'themes' directory, this directory on your machine:
   # file.path(.libPaths(), "csasdown", "themes")
   # to your working directory (the one containing index.Rmd)
   # To change the foreground text color, change the RGB value in the line containing
   # 'DefineVerbatimEnvironment'
   # To change background color, change the RGB values in the line containing 'shadecolor'
   highlight: tango
# ------------
# End of options to set
knit: (function(input, ...) {
       csasdown::render('_bookdown.yml')
      })
link-citations: true
bibliography: bib/refs.bib
# Any extra LaTeX code for the header:
header-includes:
  - \usepackage{amsmath}
---

```{r setup, echo=FALSE, cache=FALSE, message=FALSE, results='hide', warning=FALSE}
library(knitr)
if (is_latex_output()) {
  knitr_figs_dir <- "knitr-figs-pdf/"
  knitr_cache_dir <- "knitr-cache-pdf/"
  fig_out_type <- "png"
} else {
  knitr_figs_dir <- "knitr-figs-docx/"
  knitr_cache_dir <- "knitr-cache-docx/"
  fig_out_type <- "png"
}
fig_asp <- 0.618
fig_width <- 8
fig_out_width <- "5.5in"
fig_dpi <- 180
fig_align <- "center"
fig_pos <- "H"
user <- Sys.info()[["user"]]
opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  results = 'hide',
  comment = "#>",
  fig.path = knitr_figs_dir,
  cache.path = knitr_cache_dir,
  fig.asp = fig_asp,
  fig.width = fig_width,
  out.width = fig_out_width,
  echo = FALSE,
  # autodep = isTRUE(user %in% "seananderson"),
  # cache = isTRUE(user %in% "seananderson"),
  cache.comments = FALSE,
  dev = fig_out_type,
  dpi = fig_dpi,
  fig.align = fig_align,
  fig.pos = fig_pos
)
options(
  # Prevent xtable from adding a timestamp comment to the table code
  # it produces
  xtable.comment = FALSE,
  # Don't allow kableExtra to load packages, we add them manually in
  # csasdown
  kableExtra.latex.load_packages = FALSE,
  # Stop chunk output (echo) running into the margins
  width = 80,
  # Don't use scientific notation (stops tables from showing 1.2e3, etc.)
  scipen = 999)
# Fixes weird bug where knitr::include_graphics() thinks the non-git folder
# is relative
options(knitr.graphics.rel_path = FALSE)
```

```{r library-setup, cache = FALSE, fig.keep='none'}
# Libraries in alphabetical order

library(devtools)
library(dplyr)
if(user == "grandin"){
  load_all("../../../gfiscamutils")
  load_all("../../../csasdown")
}else if(user == "seananderson"){
  library(gfiscamutils)
  load_all("~/src/gfiscamutils/")
  load_all("~/src/csasdown/")
} else {
  library(gfiscamutils)
  library(csasdown)
}
library(gfplot)
library(gfutilities)
library(ggplot2)
library(gridExtra)
library(here)
library(kableExtra)
library(purrr)
library(rosettafish)
library(tidylog, warn.conflicts = FALSE)
devtools::load_all(".")

meta <- rmarkdown::metadata$output
build_rds <- FALSE
if(!is.null(meta)){
  build_rds <- meta$`csasdown::resdoc_pdf`$build_rds
}
```

```{r include = FALSE}
source("load-models.R", local = knitr::knit_global())
```

```{r data-setup, cache.lazy = FALSE}
# This chunk requires that the chunk above that loads load-models.R is run

bc <- "British Columbia"
sp <- "Arrowtooth Flounder"

month_fishing_starts <- 2
day_fishing_starts <- 21

data_dir <- file.path(drs$nongit_dir, "data")
data_output_dir <- file.path(drs$nongit_dir, "data-output")

if(!dir.exists(data_dir)){
  stop("Data directory does not exist: ", data_dir, call. = FALSE)
}
iphc_file <- file.path(data_dir, "iphc-survey-index.rds")
if(!file.exists(iphc_file)){
  stop("IPHC file does not exist: ", iphc_file, call. = FALSE)
}
discard_cpue_file <- file.path(data_dir,
"cpue-predictions-arrowtooth-flounder-modern-3CD5ABCDE-discard-july-26-feb-fishing-year.csv")
#"cpue-predictions-arrowtooth-flounder-modern-3CD5ABCDE-discard-july-26-jan-1-year.csv")
if(!file.exists(discard_cpue_file)){
  stop("Discard CPUE file does not exist: ", discard_cpue_file, call. = FALSE)
}
stitched_syn_file <- file.path(data_dir, "stitched-syn-index.rds")
if(!file.exists(stitched_syn_file)){
  stop("Stitched Synoptics file does not exist: ", stitched_syn_file, call. = FALSE)
}

iphc <- readRDS(iphc_file)$series_ABCD_full$ser_longest
discard_cpue <- read_csv(discard_cpue_file)
stitched_syn <- readRDS(stitched_syn_file)

dat <- readRDS(file.path(drs$nongit_dir, "data",
                         "arrowtooth-flounder-aug11-2022.rds"))

# Remove 2014 WCHG index point
wchg_2014_row <- 
  dat$survey_index$survey_abbrev == "SYN WCHG" & dat$survey_index$year == 2014
if(any(wchg_2014_row)){
  dat$survey_index <- dat$survey_index[-which(wchg_2014_row), ]
}

# These must be removed for call to add_extra_indices()
survey_index <- dat$survey_index %>% 
  select(-species_common_name, -species_science_name)
survey_index <- add_extra_indices(survey_index, 
                                  iphc = iphc,
                                  discard_cpue = discard_cpue,
                                  stitched_syn = stitched_syn)

# Areas 3CD and 5ABCDE only 
major_areas <- c("03","04", "05", "06", "07", "08", "09")
tidy_areas <- c("3[CD]+", "5[ABCDE]+")
survey_sets <- dat$survey_sets |> 
  filter(major_stat_area_code %in% major_areas)
survey_samples <- dat$survey_samples |> 
  filter(major_stat_area_code %in% major_areas)
survey_samples_syn <- survey_samples |> 
  filter(survey_abbrev %in% c("SYN QCS",
                              "SYN HS",
                              "SYN WCVI",
                              "SYN WCHG"))
commercial_samples <- dat$commercial_samples |> 
  filter(major_stat_area_code %in% major_areas)
comm_ft <- extract_fleet_samples(commercial_samples)
comm_ss <- extract_fleet_samples(commercial_samples, include = FALSE)

# Aggregated commercial catch
month_start <- 2
day_start <- 21
catch <- tidy_catch(dat$catch,
                    areas = tidy_areas,
                    month_fishing_starts = month_start,
                    day_fishing_starts = day_start)
# Catch by fleet
catch_ft <- extract_fleet_catch(dat$catch) |> 
  tidy_catch(areas = tidy_areas,
             month_fishing_starts = month_start,
             day_fishing_starts = day_start)

catch_ss <- extract_fleet_catch(dat$catch, include = FALSE) |> 
  tidy_catch(areas = tidy_areas,
             month_fishing_starts = month_start,
             day_fishing_starts = day_start)

cpue_spatial <- dat$cpue_spatial
cpue_spatial_ll <- dat$cpue_spatial_ll
age_precision <- dat$age_precision

theme_set(gfiscam_theme())

# Gear names are set in the data file for each model
gear_names <- models$base_model[[1]]$dat$gear_names
if(fr()){
  # Translate all gear names to French
  # Note 'Shoreside' is the same in both languages 
  gear_names_fr <- map_chr(gear_names, ~{
    if(.x == "HS Multispecies Assemblage"){
      return("HS Assemblage multi-espèces")
    }
    if(grepl("Synoptic", .x)){
      j <- str_split(.x, " ")[[1]]
      paste(j[1], tr(j[2]))
    }else{
      tr(.x)
    }
  })
  
  models$base_model <- 
    replace_gear_names(models$base_model,
                       old_gear_names = gear_names,
                       new_gear_names = gear_names_fr)
  models$bridge_grps[[1]] <- 
    replace_gear_names(models$bridge_grps[[1]],
                       old_gear_names = gear_names,
                       new_gear_names = gear_names_fr)
  models$bridge_grps[[2]] <- 
    replace_gear_names(models$bridge_grps[[2]],
                       old_gear_names = gear_names,
                       new_gear_names = gear_names_fr)
}

base_model <- models$base_model[[1]]

base_all_gears <- gear_lu_table(base_model, "all")
base_age_gears <- gear_lu_table(base_model, "age")
base_index_gears <- gear_lu_table(base_model, "index")
base_fleet_gears <- gear_lu_table(base_model, "fleet")

mcmc_chain_length <- 10000000
mcmc_num_samples <- 2000
mcmc_sample_freq <- mcmc_chain_length / mcmc_num_samples
mcmc_burn_in <- 1000
mcmc_actual_samples <- mcmc_num_samples - mcmc_burn_in

qcs <- "Queen Charlotte Sound Synoptic Survey"
hsmas <- "Hecate Strait Multispecies Assemblage Survey"
hss <- "Hecate Strait Synoptic Survey"
wcvis <- "West Coast Vancouver Island Synoptic Survey"
wchgs <- "West Coast Haida Gwaii Synoptic Survey"
dcpue <- "Discard CPUE Index"

la <- "2015 assessment"
tv_block1 <- paste0(unique(filter(base_model$mcmccalcs$selest_quants,
                                  gear == "QCS Synoptic", block == 1)$start_year),
                    "--", 
                    unique(filter(base_model$mcmccalcs$selest_quants,
                                  gear == "QCS Synoptic", block == 1)$end_year))
tv_block2 <- paste0(unique(filter(base_model$mcmccalcs$selest_quants,
                                  gear == "QCS Synoptic", block == 2)$start_year),
                    "--", 
                    unique(filter(base_model$mcmccalcs$selest_quants,
                                  gear == "QCS Synoptic", block == 2)$end_year))
# Text for selectivity block year ranges
qcs_tv_yr_start <- base_model$ctl$start.yr.time.block[3, ]
qcs_tv_yr_start[1] <- base_model$dat$start.yr
qcs_tv_yr_end <- c(qcs_tv_yr_start[2:length(qcs_tv_yr_start)] - 1,
                   base_model$dat$end.yr)
if(length(qcs_tv_yr_start) == 2){
  qcs_sel_ranges <- paste(paste0(qcs_tv_yr_start, "-", qcs_tv_yr_end),
                          collapse = " and ")
}else{
  qcs_sel_ranges <- paste0(qcs_tv_yr_start, "-", qcs_tv_yr_end)
  tmp <- qcs_sel_ranges[length(qcs_sel_ranges)]
  qcs_sel_ranges <- paste(qcs_sel_ranges[-length(qcs_sel_ranges)],
                          collapse = ", ")
  qcs_sel_ranges <- paste0(qcs_sel_ranges, ", and ", tmp)
}

# Number of parameters estimated (from PAR file)
num_params <- base_model$par |>
  map_dbl(~{j <- strsplit(as.character(.x), split = " ")[[1]]
  j <- j[j != ""]
  length(j)
  }) |> sum()

# Catch table
ct <- as_tibble(base_model$dat$catch)
ct_start_yr <- min(ct$year)
ct_end_yr <- max(ct$year)

# Reference points (table values)
ref_pts <- as_tibble(base_model$mcmccalcs$params_quants)

# Projected biomass
end_yr <- base_model$dat$end.yr
assess_yr <- end_yr + 1
proj_yr <- assess_yr + 1
sbt_quants <- as_tibble(base_model$mcmccalcs$sbt_quants)
proj_bio <- sbt_quants[, as.character(assess_yr)] |> pull()

# Fishing mortality
f_max_by_gear <- map_dbl(base_model$mcmccalcs$ft_quants, ~{
  max(.x[2,])
})
f_max <- max(f_max_by_gear)
which_f_max <- which(f_max == f_max_by_gear)
which_f_max_gear <- base_model$dat$fleet_gear_names[which_f_max]
which_f_max_yr <- names(which(base_model$mcmccalcs$ft_quants[[which_f_max]][2, ] == f_max))

f_ci <- base_model$mcmccalcs$ft_quants[[which_f_max]][, base_model$mcmccalcs$ft_quants[[which_f_max]][2, ] == f_max]

# Relative spawning biomass
depl_end <- as_tibble(base_model$mcmccalcs$depl_quants) |>
  select(!!sym(as.character(assess_yr))) |> 
  pull()

# Decision table values - B_2023 < B_2022
table_dec <- table_decisions(base_model, ret_df = TRUE)
probs_catch_0 <- table_dec |> filter(tac == 0) |> unlist()
probs_catch_10 <- table_dec |> filter(tac == 10) |> unlist()
probs_catch_50 <- table_dec |> filter(tac == 50) |> unlist()
prob_proj_less_assess_0 <- probs_catch_0[length(probs_catch_0)]
prob_proj_less_assess_10 <- probs_catch_10[length(probs_catch_10)]
prob_proj_less_assess_50 <- probs_catch_50[length(probs_catch_50)]

probs_proj_less_assess <- table_dec[, ncol(table_dec)] |>
  pull() |> 
  as.numeric()
which_prob_less_50_50 <- which(probs_proj_less_assess < 0.5)
which_prob_less_50_50 <- which_prob_less_50_50[length(which_prob_less_50_50)]
prob_less_50_50 <- table_dec[which_prob_less_50_50, ]
prob_greater_50_50 <- table_dec[which_prob_less_50_50 + 1, ]

val_less_50_50 <- pull(prob_less_50_50[, ncol(prob_less_50_50)])

# Decision table values - B_2023 < 0.4B0
below_04bo <- table_dec |> 
  select(paste0(proj_yr, "_04bo")) |> 
  pull() |> 
  as.numeric()
range_below_04bo <- c(min(below_04bo), max(below_04bo))

# Decision table values - B_2023 < 0.2B0
below_02bo <- table_dec |> 
  select(paste0(proj_yr, "_02bo")) |> 
  pull() |> 
  as.numeric()
range_below_02bo <- c(min(below_02bo), max(below_02bo))
which_prob_greater_50_50_02bo <- which(below_02bo > 0.5)[1]
prob_greater_50_50_02bo <- below_02bo[which_prob_greater_50_50_02bo]
row_greater_50_50_02bo <- table_dec[which_prob_greater_50_50_02bo, ]

# Decision table values - B_2023 < 0.8BMSY
below_08bmsy <- table_dec |> 
  select(paste0(proj_yr, "_08bmsy")) |> 
  pull() |> 
  as.numeric()
range_below_08bmsy <- c(min(below_08bmsy), max(below_08bmsy))

# Decision table values - B_2023 < 0.4BMSY
below_04bmsy <- table_dec |> 
  select(paste0(proj_yr, "_04bmsy")) |> 
  pull() |> 
  as.numeric()
range_below_04bmsy <- c(min(below_04bmsy), max(below_04bmsy))
```

```{r biological-params}

find_length_outliers <- function(xx) {
  yy <- stats::pnorm(xx,
    mean = mean(xx, na.rm = TRUE),
    sd = stats::sd(xx, na.rm = TRUE), log.p = TRUE
  )
  zz <- stats::qnorm(yy, log.p = TRUE)
  out <- zz[zz > 4 & !is.na(zz)]
  if (length(out) > 1L) {
    return(xx[which(zz > 4)])
  } else {
    return(numeric(0))
  }
}

length_samples_survey <- filter(
  dat$survey_samples,
  !length %in% find_length_outliers(dat$survey_samples$length)
)

length_samples_ft <- filter(
  comm_ft,
  !length %in% find_length_outliers(comm_ft$length)
)

length_samples_ss <- filter(
  comm_ss,
  !length %in% find_length_outliers(comm_ss$length)
)

all_length_samples <- bind_rows(length_samples_survey, length_samples_ft, length_samples_ss)

all_age_samples <- bind_rows(dat$survey_samples, comm_ft, comm_ss) %>%
  filter(!is.na(age) & age < 40)
# it seems there's one extreme outlier... 50 y, also size and sex wouldn't make sense so definite error

# TODO: should the reported values (and coastwide plot) be for just from the 4 trawl surveys combined? Doesn't seem to fit as well if commercial samples added. 
#vb_m <- fit_vb(dat$survey_samples %>% filter(survey_series_id %in% c(1, 3, 4, 16)), 
#               sex = "male", method = "tmb", too_high_quantile = 1)

#vb_f <- fit_vb(dat$survey_samples %>% filter(survey_series_id %in% c(1, 3, 4, 16)), 
#               sex = "female", method = "tmb", too_high_quantile = 1)

#mat_fit <- fit_mat_ogive(dat$survey_samples %>% filter(survey_series_id %in% c(1, 3, 4, 16)), 
#                         type = "age", sample_id_re = TRUE, year_re = FALSE)
#                     
# Use function from this package as it is (very) slightly different than what 
# fit_mat_ogive() returns, and is what is input into the model
mat_fit <- export_mat_lw_age(dat$survey_samples, write_file = FALSE)
# TODO: what random effects wanted? If year, than params are saved as mat_fit$mat_perc$mean$f.mean.p0.5 and mat_fit$mat_perc$mean$m.mean.p0.5 instead of mat_fit$mat_perc$f.p0.5 and mat_fit$mat_perc$m.p0.5. I assume fig:fig-mat should also be made to match 

# Natural mortality values in the control file

param_ctl_table <- models$bridge_grps[[3]][[2]]$ctl$params |> as_tibble(rownames = "param")
male_m_ctl <- exp(param_ctl_table |> filter(param == "log_m_male") |> pull(ival))
female_m_ctl <- exp(param_ctl_table |> filter(param == "log_m_female") |> pull(ival))
```

```{r proportion-female}

if(!exists("data_dir")){
  stop("`data_dir` does not exist. If running from command line, ",
       "source('index.Rmd') to set up all project variables", call. = FALSE)
}

prop_female_fn <- file.path(data_dir, "prop_female_output.rds")
if(file.exists(prop_female_fn)){
  prop_female_lst <- readRDS(prop_female_fn)
}else{
  comm_prop <- props_comm(dat$commercial_samples)
  surv_prop <- props_surv(surv_series = c(1, 3, 4, 16),
                          surv_series_names = c("qcsss", "hsss", "wcviss", "wchgss"),
                          surv_samples = dat$survey_samples,
                          surv_sets = dat$survey_sets)
  prop_female_lst <- list(comm_prop, surv_prop)
  saveRDS(prop_female_lst, prop_female_fn)
}

prop_female_table <- table_prop_female(prop_female_lst, return_df = TRUE)
total_prop_female <- f(100 * tail(prop_female_table, 1)[-1] |>
                         unlist() |>
                         as.numeric() |>
                         mean(),
                       0)
```
