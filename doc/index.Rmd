---
title: "Arrowtooth Flounder (*Atheresthes stomias*) Stock Assessment for the West Coast of British Columbia in 2021"
french_title: "Évaluation du stock de la plie à dents de flèche (Atheresthes stomias) sur la côte ouest de la Colombie-Britannique en 2021 Colombie-Britannique en 2021"
author: |
  Chris J. Grandin^1^ and
  Sean C. Anderson^1^
author_list: "Grandin, C.J. and Anderson, S.C."
address: |
  ^1^Pacific Biological Station\
     Fisheries and Oceans Canada, 3190 Hammond Bay Road\
     Nanaimo, British Columbia, V9T 6N7, Canada
french_address: |
  ^1^Station biologique du Pacifique\
     Pêches et Océans Canada, 3190 Hammond Bay Road\
     Nanaimo, Colombie-Britannique, V9T 6N7, Canada\
  \smallskip
  ^2^Loin, très loin\
     Une autre galaxie
month: October
french_month: Octobre
year: 2021
report_number: nnn
region: Pacific Region
french_region: "Région du Pacifique"
isbn: "978-0-660-38322-4"
cat_no: "Fs70-6/2021-012E-PDF"
citation_other_language: "Grandin, C.J. et Anderson, S.C. Title Here (*Latin Species Name*). DFO Secr. can. de consult. sci. du MPO. Doc. de rech 2019/nnn. iv + 13 p."

abstract: |
  Arrowtooth Flounder (*Atheresthes stomias*, Turbot) are an important component of the bottom trawl fishery in British Columbia. They are managed as a coastwide stock, with a TAC of 4,000 t and catch of 10,679 t in 2014. Prior to the introduction of freezer trawlers in the mid-2000s, most of the historical catch of Arrowtooth Flounder is understood to have been discarded at sea. This was largely due to proteolysis, which occurs in the muscle tissue of this species a short time after it is caught, making the flesh unpalatable.

  In the past decade, markets have been established for fillets that have been frozen at sea, and the freezer trawl fleet has taken an increasing proportion of the coastwide catch.

french_abstract: |
  La plie à dents de flèche (*Atheresthes stomias*, Turbot) est une composante importante de la pêche au chalut de fond en Colombie-Britannique. Elle est gérée comme un stock de toute la côte, avec un TAC de 4 000 t et des prises de 10 679 t en 2014. Avant l'introduction des chalutiers congélateurs au milieu des années 2000, on comprend que la plupart des prises historiques de la limande à dents de flèche étaient rejetées en mer. Cela était dû en grande partie à la protéolyse, qui se produit dans le tissu musculaire de cette espèce peu de temps après la capture, rendant la chair peu appétissante.
  
  Au cours de la dernière décennie, des marchés ont été créés pour les filets qui ont été congelés en mer, et la flotte de chalutiers congélateurs a pris une proportion croissante des prises côtières. Traduit avec www.DeepL.com/Translator (version gratuite)

header: "Draft working paper --- Do not cite or circulate" # or "" to omit
output:
 csasdown::resdoc_pdf:
   # build_rds is a toggle to re-build all the RDS files for the models
   build_rds: false
   keep_md: true
   french: false
   # copy_sty is a toggle to copy the style file from the csasdown package every time you compile
   # the document. If false, any changes you have made to the style file in your project
   # will remain between compilations. If true, your changes will be lost when you compile
   copy_sty: true
   # line_nums is a toggle to show line numbers on the left side of the page. 
   line_nums: true
   # line_nums_mod represents showing every Nth line if line_nums is true
   line_nums_mod: 1
   # lot_lof is a toggle to show/not show the lists of tables and figures at the
   # beginning of the document
   lot_lof: false
   # draft_watermark is a toggle to show/not show a DRAFT watermark across every page
   draft_watermark: false
   # include_section_nums, if true includes section numbering in the document body,
   # if false, no numbering in the document body but the TOC will still show numbering
   include_section_nums: true
   # highlight is the theme to use for code output. Must be one of the list given by:
   # pandoc --list-highlight-styles
   # which are:
   # pygments, tango, espresso, zenburn, kate, monochrome, breezedark, haddock
   # or the name of a custom *.latex file which is most easily made by copying one from 
   # the csasdown library 'themes' directory, this directory on your machine:
   # file.path(.libPaths(), "csasdown", "themes")
   # to your working directory (the one containing index.Rmd)
   # To change the foreground text color, change the RGB value in the line containing
   # 'DefineVerbatimEnvironment'
   # To change background color, change the RGB values in the line containing 'shadecolor'
   highlight: tango
# ------------
# End of options to set
knit: (function(input, ...) {
       csasdown::render('_bookdown.yml')
      })
link-citations: true
bibliography: bib/refs.bib
# Any extra LaTeX code for the header:
# header-includes:
# - \usepackage{tikz}
---

```{r setup, echo=FALSE, cache=FALSE, message=FALSE, results='hide', warning=FALSE}
library(knitr)
if (is_latex_output()) {
  knitr_figs_dir <- "knitr-figs-pdf/"
  knitr_cache_dir <- "knitr-cache-pdf/"
  fig_out_type <- "png"
} else {
  knitr_figs_dir <- "knitr-figs-docx/"
  knitr_cache_dir <- "knitr-cache-docx/"
  fig_out_type <- "png"
}
fig_asp <- 0.618
fig_width <- 9
fig_out_width <- "5.5in"
fig_dpi <- 180
fig_align <- "center"
fig_pos <- "H"
user <- Sys.info()[["user"]]
opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  results = 'hide',
  comment = "#>",
  fig.path = knitr_figs_dir,
  cache.path = knitr_cache_dir,
  fig.asp = fig_asp,
  fig.width = fig_width,
  out.width = fig_out_width,
  echo = FALSE,
  # autodep = isTRUE(user %in% "seananderson"),
  # cache = isTRUE(user %in% "seananderson"),
  cache.comments = FALSE,
  dev = fig_out_type,
  dpi = fig_dpi,
  fig.align = fig_align,
  fig.pos = fig_pos
)
options(# Prevent xtable from adding a timestamp comment to the table code it produces
        xtable.comment = FALSE,
        # Don't allow kableExtra to load packages, we add them manually in csasdown
        kableExtra.latex.load_packages = FALSE,
        # Stop chunk output (echo) running into the margins
        width = 80,
        # Don't use scientific notation (stops tables from showing 1.2e3, etc.)
        scipen = 999)
options("knitr.graphics.rel_path" = FALSE) # Fixes weird bug where knitr::include_graphics() thinks the non-git folder is relative!??
```

```{r library-setup, cache = FALSE, fig.keep='none'}
# Libraries in alphabetical order

library(devtools)
library(dplyr)
if(user == "grandin"){
  load_all("D:/github/pbs-assess/gfiscamutils/")
  load_all("D:/github/pbs-assess/csasdown/")
}else if(user == "seananderson"){
  library(gfiscamutils)
  load_all("~/src/gfiscamutils/")
  load_all("~/src/csasdown/")
} else {
  library(gfiscamutils)
  library(csasdown)
}
library(gfplot)
library(gfutilities)
library(ggplot2)
library(gridExtra)
library(here)
library(kableExtra)
library(purrr)
library(rosettafish)
library(tidylog, warn.conflicts = FALSE)
devtools::load_all(".")

meta <- rmarkdown::metadata$output
build_rds <- FALSE
if(!is.null(meta)){
  build_rds <- meta$`csasdown::resdoc_pdf`$build_rds
}
```

```{r model-setup, cache.lazy = FALSE}
# These are in rosettafish so don't need french versions here
bc <- "British Columbia"
sp <- "Arrowtooth Flounder"

# This is a list of vectors of bridge groups (bridge models that will be
# plotted against each other). It can be `NULL` if to be ignored.
bridge_models_dirs <- 
  list(c("01-base-2015",
         "02-bridge-update-data-to-2014",
         "03-bridge-update-data-to-2021",
         "04-bridge-add-wchg"),
       c("05-bridge-switch-to-dm-likelihood",
         "06-bridge-switch-to-2-fleet-model",
         "07-bridge-add-discard-cpue",
         "08-bridge-switch-to-split-sex",
         "09-bridge-switch-fishing-year-to-feb-21-feb-20"))

bridge_models_text <- 
  list(c("2015 Base model (one fleet, single sex)",
         "Update data to 2014 (one fleet, single sex)",
         "Update data to 2021 (one fleet, single sex)",
         "Add WCHG survey index and age comps"),
       c("Switch to DM likelihood (one fleet, single sex)",
         "Change to two-fleet model (two fleet, single sex)",
         "Add Discard CPUE index (two fleets, single sex)",
         "Convert model to split sex (two fleets, split sex)",
         "Change fishing year to Feb 21 - Feb 20 (two fleets, split sex)"))

# Make these factors so that they can be reordered in the legends later
bridge_models_text <- bridge_models_text %>% map(~{factor(.x, levels = .x)})

# This is a list of vectors of sensitivity groups (sensitivity models that
# will be plotted against each other). It can be `NULL` if to be ignored.
# The base model will be prepended to each group later in set_dirs() so that
# it is first on the plots for each group.
sens_models_dirs <-
  list(c("01-sigma-0.1",
         "02-estimate-total-variance"),
       c("03-tau-1.0",
         "04-tau-0.6"),
       c("05-low-steepness"),
       c("06-m-female-tight-prior",
         "07-m-female-loose-prior"),
       c("08-m-male-tight-prior",
         "09-m-male-loose-prior"),
       c("10-qk-mean-1.0",
         "11-qk-loose-prior"),
       c("12-selex-equal-maturity"))
sens_models_text <-
  list(c(ifelse(fr(),
                "Diminuer $\\sigma$ à 0,1",
                "Decrease $\\sigma$ to 0.1"),
         ifelse(fr(),
                "Estimation de la variance totale",
                "Estimate total variance")),
       c(ifelse(fr(),
                "Augmenter $\\tau$ à 1,0",
                "Increase $\\tau$ to 1.0"),
         ifelse(fr(),
                "Diminuer $\\tau$ de 0,6",
                "Decrease $\\tau$ to 0.6")),
       c(ifelse(fr(),
                "Diminuer la moyenne de $h$ avant 0,72",
                "Decrease mean of $h$ prior to 0.72")),
       c(ifelse(fr(),
                "Priorité plus stricte sur $M_\\mathrm{Femelle}$",
                "Tighter prior on $M_\\mathrm{Female}$"),
         ifelse(fr(), 
                "Priorité plus lâche sur $M_\\mathrm{Femelle}$",
                "Looser prior on $M_\\mathrm{Female}$")),
       c(ifelse(fr(),
                "Priorité plus stricte sur $M_\\mathrm{M\\hat{a}le}$",
                "Tighter prior on $M_\\mathrm{Male}$"),
         ifelse(fr(),
                "Priorité plus faible sur $M_\\mathrm{M\\hat{a}le}$",
                "Looser prior on $M_\\mathrm{Male}$")),
       c(ifelse(fr(),
                "Augmenter la moyenne antérieure de $q_\\mathrm{k}$ à 1,0",
                "Increase $q_\\mathrm{k}$ prior mean to 1.0"),
         ifelse(fr(),
                "Priorité plus faible sur $q_\\mathrm{k}$",
                "Looser prior on $q_\\mathrm{k}$")),
       c(ifelse(fr(),
                "Courbe de sélectivité égale à l'ogive de maturité",
                "Selectivity curve equals maturity ogive")))

# This will be used to generate the sensitivity parameter table later
sens_models_text_no_base <- sens_models_text

# Add base model text to each sensitivity group
sens_models_text <- map(sens_models_text, ~{c("Base model", .x)})

# Make these factors so that they can be reordered in the legends later
sens_models_text <- sens_models_text %>% map(~{factor(.x, levels = .x)})

sens_changes_text <-
  list(c("$\\vartheta^2$ = 1.538; $\\rho$ = 0.059",
         "$\\vartheta^2$ estimated; $\\rho$ = 0.059"),
       c("$\\vartheta^2$ = 0.962; $\\rho$ = 0.038",
         "$\\vartheta^2$ = 2.500; $\\rho$ = 0.100"),
       c("$h$ = Beta($\\alpha$ = 11.72, $\\beta$ = 4.56)"),
       c(ifelse(fr(),
                "ln($M_\\mathrm{Femelle}$) = Normale(ln(0.35), 0.5)",
                "ln($M_\\mathrm{Female}$) = Normal(ln(0.35), 0.5)"),
         ifelse(fr(),
                "ln($M_\\mathrm{Femelle}$) = Normale(ln(0.35), 2.5)",
                "ln($M_\\mathrm{Female}$) = Normal(ln(0.35), 2.5)")),
       c(ifelse(fr(),
                "ln($M_\\mathrm{M\\hat{a}le}$) = Normale(ln(0.2), 0.5)",
                "ln($M_\\mathrm{Male}$) = Normal(ln(0.2), 0.5)"),
         ifelse(fr(),
                "ln($M_\\mathrm{M\\hat{a}le}$) = Normale(ln(0.2), 2.5)",
                "ln($M_\\mathrm{Male}$) = Normal(ln(0.2), 2.5)")),
       c(ifelse(fr(),
                "Moyenne antérieure de $q_\\mathrm{k}$ = 1,0 pour tous les $k$",
                "$q_\\mathrm{k}$ prior mean = 1.0 for all $k$"),
         ifelse(fr(),
                "$q_\\mathrm{k}$ prior sd = 1,5 pour tous les $k$",
                "$q_\\mathrm{k}$ prior sd = 1.5 for all $k$")),
       c(ifelse(fr(),
                "Paramètres de sélectivité des pêcheries = maturité ($A_\\mathrm{50\\%}$ and $SD_\\mathrm{50\\%}$)",
                "Fishery selectivity parameters = maturity ($A_\\mathrm{50\\%}$ and $SD_\\mathrm{50\\%}$)")))

if(here() == "/home/rstudio"){
  # For an Rstudio server spawned inside a Docker container
  drs <- set_dirs(nongit_dir = file.path(dirname(here("arrowtooth")),
                                         "arrowtooth-nongit"),
                  base_model_dir = "base",
                  bridge_models_dirs = bridge_models_dirs,
                  sens_models_dirs = sens_models_dirs,
                  check_dir_exists = FALSE)
}else{
  drs <- set_dirs(base_model_dir = "base",
                  bridge_models_dirs = bridge_models_dirs,
                  sens_models_dirs = sens_models_dirs,
                  check_dir_exists = FALSE)
}

models <- model_setup(main_dirs = drs,
                      bridge_models_text = bridge_models_text,
                      sens_models_text = sens_models_text,
                      overwrite_rds_files = build_rds)

month_fishing_starts <- 2
day_fishing_starts <- 21

data_dir <- file.path(drs$nongit_dir, "data")
data_output_dir <- file.path(drs$nongit_dir, "data-output")

if(!dir.exists(data_dir)){
  stop("Data directory does not exist: ", data_dir, call. = FALSE)
}
iphc_file <- file.path(data_dir, "iphc-survey-index.rds")
if(!file.exists(iphc_file)){
  stop("IPHC file does not exist: ", iphc_file, call. = FALSE)
}
discard_cpue_file <- file.path(data_dir,
"cpue-predictions-arrowtooth-flounder-modern-3CD5ABCDE-discard-july-26-feb-fishing-year.csv")
#"cpue-predictions-arrowtooth-flounder-modern-3CD5ABCDE-discard-july-26-jan-1-year.csv")
if(!file.exists(discard_cpue_file)){
  stop("Discard CPUE file does not exist: ", discard_cpue_file, call. = FALSE)
}
stitched_syn_file <- file.path(data_dir, "stitched-syn-index.rds")
if(!file.exists(stitched_syn_file)){
  stop("Stitched Synoptics file does not exist: ", stitched_syn_file, call. = FALSE)
}

iphc <- readRDS(iphc_file)$series_ABCD_full$ser_longest
discard_cpue <- read_csv(discard_cpue_file)
stitched_syn <- readRDS(stitched_syn_file)

# dat <- readRDS(file.path(drs$nongit_dir, "data",
#                          "arrowtooth-flounder-june11-2021.rds"))
# dat <- readRDS(file.path(drs$nongit_dir, "data",
#                          "arrowtooth-flounder-oct10-2021.rds"))
dat <- readRDS(file.path(drs$nongit_dir, "data",
                         "arrowtooth-flounder-aug11-2022.rds"))

# Remove 2014 WCHG index point
wchg_2014_row <- 
  dat$survey_index$survey_abbrev == "SYN WCHG" & dat$survey_index$year == 2014
if(any(wchg_2014_row)){
  dat$survey_index <- dat$survey_index[-which(wchg_2014_row), ]
}

# These must be removed for call to add_extra_indices()
survey_index <- dat$survey_index %>% 
  select(-species_common_name, -species_science_name)
survey_index <- add_extra_indices(survey_index, 
                                  iphc = iphc,
                                  discard_cpue = discard_cpue,
                                  stitched_syn = stitched_syn)

# Areas 3CD and 5ABCDE only 
major_areas <- c("03","04", "05", "06", "07", "08", "09")
tidy_areas <- c("3[CD]+", "5[ABCDE]+")
survey_sets <- dat$survey_sets |> 
  filter(major_stat_area_code %in% major_areas)
survey_samples <- dat$survey_samples |> 
  filter(major_stat_area_code %in% major_areas)
survey_samples_syn <- survey_samples |> 
  filter(survey_abbrev %in% c("SYN QCS",
                              "SYN HS",
                              "SYN WCVI",
                              "SYN WCHG"))
commercial_samples <- dat$commercial_samples |> 
  filter(major_stat_area_code %in% major_areas)
comm_ft <- extract_fleet_samples(commercial_samples)
comm_ss <- extract_fleet_samples(commercial_samples, include = FALSE)

# Total catch
catch <- tidy_catch(dat$catch, areas = tidy_areas)
# Catch by fleet
catch_ft <- extract_fleet_catch(dat$catch) #|> 
  #tidy_catch(areas = c("3[CD]+", "5[ABCDE]+"))
catch_ss <- extract_fleet_catch(dat$catch, include = FALSE) #|> 
  #tidy_catch(areas = c("3[CD]+", "5[ABCDE]+"))

cpue_spatial <- dat$cpue_spatial
cpue_spatial_ll <- dat$cpue_spatial_ll
age_precision <- dat$age_precision

theme_set(gfiscam_theme())

# Gear names are set in the data file for each model
# Make the commercial gear names be Freezer Trawlers and Shoreside
models$base_model <- 
  replace_gear_names(models$base_model,
                     old_gear_names = c("Freezer", "Wet boats"),
                     new_gear_names = c("Freezer Trawlers", "Shoreside"),
                     old_gear_abbrevs = "WB COMM",
                     new_gear_abbrevs = "SS COMM")

models$bridge_grps[[1]] <- 
  replace_gear_names(models$bridge_grps[[1]],
                     old_gear_names = c("Freezer", "Wet boats"),
                     new_gear_names = c("Freezer Trawlers", "Shoreside"),
                     old_gear_abbrevs = "WB COMM",
                     new_gear_abbrevs = "SS COMM")

models$bridge_grps[[2]] <- 
  replace_gear_names(models$bridge_grps[[2]],
                     old_gear_names = c("Freezer", "Wet boats"),
                     new_gear_names = c("Freezer Trawlers", "Shoreside"),
                     old_gear_abbrevs = "WB COMM",
                     new_gear_abbrevs = "SS COMM")

gear_names <- models$base_model[[1]]$dat$gear_names
if(fr()){
  # Translate all gear names to French
  # Note 'Shoreside' is the same in both languages 
  gear_names_fr <- map_chr(gear_names, ~{
    if(.x == "HS Multispecies Assemblage"){
      return("HS Assemblage multi-espèces")
    }
    if(grepl("Synoptic", .x)){
      j <- str_split(.x, " ")[[1]]
      paste(j[1], en2fr(j[2]))
    }else{
      en2fr(.x)
    }
  })
  
  models$base_model <- 
    replace_gear_names(models$base_model,
                       old_gear_names = gear_names,
                       new_gear_names = gear_names_fr)
  models$bridge_grps[[1]] <- 
    replace_gear_names(models$bridge_grps[[1]],
                       old_gear_names = gear_names,
                       new_gear_names = gear_names_fr)
  models$bridge_grps[[2]] <- 
    replace_gear_names(models$bridge_grps[[2]],
                       old_gear_names = gear_names,
                       new_gear_names = gear_names_fr)
}

base_model <- models$base_model[[1]]

base_all_gears <- gear_lu_table(base_model, "all")
base_age_gears <- gear_lu_table(base_model, "age")
base_index_gears <- gear_lu_table(base_model, "index")
base_fleet_gears <- gear_lu_table(base_model, "fleet")

mcmc_chain_length <- 400000
mcmc_sample_freq <- 200
mcmc_num_samples <- 2000

qcs <- "Queen Charlotte Sound Synoptic Survey"
hsmas <- "Hecate Strait Multispecies Assemblage Survey"
hss <- "Hecate Strait Synoptic Survey"
wcvis <- "West Coast Vancouver Island Synoptic Survey"
wchgs <- "West Coast Haida Gwaii Synoptic Survey"
dcpue <- "Discard CPUE Index"

# Text for selectivity block year ranges
qcs_tv_yr_start <- base_model$ctl$start.yr.time.block[3, ]
qcs_tv_yr_start[1] <- base_model$dat$start.yr
qcs_tv_yr_end <- c(qcs_tv_yr_start[2:length(qcs_tv_yr_start)] - 1,
                   base_model$dat$end.yr)
if(length(qcs_tv_yr_start) == 2){
  qcs_sel_ranges <- paste(paste0(qcs_tv_yr_start, "-", qcs_tv_yr_end),
                          collapse = " and ")
}else{
  qcs_sel_ranges <- paste0(qcs_tv_yr_start, "-", qcs_tv_yr_end)
  tmp <- qcs_sel_ranges[length(qcs_sel_ranges)]
  qcs_sel_ranges <- paste(qcs_sel_ranges[-length(qcs_sel_ranges)],
                          collapse = ", ")
  qcs_sel_ranges <- paste0(qcs_sel_ranges, ", and ", tmp)
}

# Number of parameters estimated (from PAR file)
num_params <- base_model$par |>
  map_dbl(~{j <- strsplit(as.character(.x), split = " ")[[1]]
  j <- j[j != ""]
  length(j)
  }) |> sum()

# Catch table
ct <- as_tibble(base_model$dat$catch)
ct_start_yr <- min(ct$year)
ct_end_yr <- max(ct$year)

# Reference points (table values)
ref_pts <- as_tibble(base_model$mcmccalcs$params_quants)

# Projected biomass
end_yr <- base_model$dat$end.yr
assess_yr <- end_yr + 1
proj_yr <- assess_yr + 1
sbt_quants <- as_tibble(base_model$mcmccalcs$sbt_quants)
proj_bio <- sbt_quants[, as.character(assess_yr)] |> pull()

# Fishing mortality
f_max_by_gear <- map_dbl(base_model$mcmccalcs$ft_quants, ~{
  max(.x[2,])
})
f_max <- max(f_max_by_gear)
which_f_max <- which(f_max == f_max_by_gear)
which_f_max_gear <- base_model$dat$fleet_gear_names[which_f_max]
which_f_max_yr <- names(which(base_model$mcmccalcs$ft_quants[[which_f_max]][2, ] == f_max))

f_ci <- base_model$mcmccalcs$ft_quants[[which_f_max]][, base_model$mcmccalcs$ft_quants[[which_f_max]][2, ] == f_max]

# Relative spawning biomass
depl_end <- as_tibble(base_model$mcmccalcs$depl_quants) |>
  select(!!sym(as.character(assess_yr))) |> 
  pull()

# Decision table values - B_2023 < B_2022
table_dec <- table_decisions(base_model, ret_df = TRUE)
probs_catch_0 <- table_dec |> filter(tac == 0) |> unlist()
probs_catch_10 <- table_dec |> filter(tac == 10) |> unlist()
probs_catch_50 <- table_dec |> filter(tac == 50) |> unlist()
prob_proj_less_assess_0 <- probs_catch_0[length(probs_catch_0)]
prob_proj_less_assess_10 <- probs_catch_10[length(probs_catch_10)]
prob_proj_less_assess_50 <- probs_catch_50[length(probs_catch_50)]

probs_proj_less_assess <- table_dec[, ncol(table_dec)] |>
  pull() |> 
  as.numeric()
which_prob_less_50_50 <- which(probs_proj_less_assess < 0.5)
which_prob_less_50_50 <- which_prob_less_50_50[length(which_prob_less_50_50)]
prob_less_50_50 <- table_dec[which_prob_less_50_50, ]
prob_greater_50_50 <- table_dec[which_prob_less_50_50 + 1, ]

val_less_50_50 <- pull(prob_less_50_50[, ncol(prob_less_50_50)])

# Decision table values - B_2023 < 0.4B0
below_04bo <- table_dec |> 
  select(paste0(proj_yr, "_04bo")) |> 
  pull() |> 
  as.numeric()
range_below_04bo <- c(min(below_04bo), max(below_04bo))

# Decision table values - B_2023 < 0.2B0
below_02bo <- table_dec |> 
  select(paste0(proj_yr, "_02bo")) |> 
  pull() |> 
  as.numeric()
range_below_02bo <- c(min(below_02bo), max(below_02bo))
which_prob_greater_50_50_02bo <- which(below_02bo > 0.5)[1]
prob_greater_50_50_02bo <- below_02bo[which_prob_greater_50_50_02bo]
row_greater_50_50_02bo <- table_dec[which_prob_greater_50_50_02bo, ]

# Decision table values - B_2023 < 0.8BMSY
below_08bmsy <- table_dec |> 
  select(paste0(proj_yr, "_08bmsy")) |> 
  pull() |> 
  as.numeric()
range_below_08bmsy <- c(min(below_08bmsy), max(below_08bmsy))

# Decision table values - B_2023 < 0.4BMSY
below_04bmsy <- table_dec |> 
  select(paste0(proj_yr, "_04bmsy")) |> 
  pull() |> 
  as.numeric()
range_below_04bmsy <- c(min(below_04bmsy), max(below_04bmsy))


# Data extraction for iSCAM models:
# extract_survey_indices(survey_index, 
#                        iphc = iphc,
#                        discard_cpue = discard_cpue,
#                        stitched_syn = stitched_syn,
#                        data_path = data_output_dir)

```

```{r biological-params}

find_length_outliers <- function(xx) {
  yy <- stats::pnorm(xx,
    mean = mean(xx, na.rm = TRUE),
    sd = stats::sd(xx, na.rm = TRUE), log.p = TRUE
  )
  zz <- stats::qnorm(yy, log.p = TRUE)
  out <- zz[zz > 4 & !is.na(zz)]
  if (length(out) > 1L) {
    return(xx[which(zz > 4)])
  } else {
    return(numeric(0))
  }
}

length_samples_survey <- filter(
  dat$survey_samples,
  !length %in% find_length_outliers(dat$survey_samples$length)
)

length_samples_ft <- filter(
  comm_ft,
  !length %in% find_length_outliers(comm_ft$length)
)

length_samples_ss <- filter(
  comm_ss,
  !length %in% find_length_outliers(comm_ss$length)
)

all_length_samples <- bind_rows(length_samples_survey, length_samples_ft, length_samples_ss)

all_age_samples <- bind_rows(dat$survey_samples, comm_ft, comm_ss) %>%
  filter(!is.na(age) & age < 40)
# it seems there's one extreme outlier... 50 y, also size and sex wouldn't make sense so definite error

# TODO: should the reported values (and coastwide plot) be for just from the 4 trawl surveys combined? Doesn't seem to fit as well if commercial samples added. 
#vb_m <- fit_vb(dat$survey_samples %>% filter(survey_series_id %in% c(1, 3, 4, 16)), 
#               sex = "male", method = "tmb", too_high_quantile = 1)

#vb_f <- fit_vb(dat$survey_samples %>% filter(survey_series_id %in% c(1, 3, 4, 16)), 
#               sex = "female", method = "tmb", too_high_quantile = 1)

#mat_fit <- fit_mat_ogive(dat$survey_samples %>% filter(survey_series_id %in% c(1, 3, 4, 16)), 
#                         type = "age", sample_id_re = TRUE, year_re = FALSE)
#                     
# Use function from this package as it is (very) slightly different than what 
# fit_mat_ogive() returns, and is what is input into the model
mat_fit <- export_mat_lw_age(dat$survey_samples, write_file = FALSE)
# TODO: what random effects wanted? If year, than params are saved as mat_fit$mat_perc$mean$f.mean.p0.5 and mat_fit$mat_perc$mean$m.mean.p0.5 instead of mat_fit$mat_perc$f.p0.5 and mat_fit$mat_perc$m.p0.5. I assume fig:fig-mat should also be made to match 
```
